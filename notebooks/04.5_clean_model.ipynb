{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["ynaUY67Zu-jI"],"authorship_tag":"ABX9TyNlAUtuQWHpluFO/5o7kpRM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"ynaUY67Zu-jI"}},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"id":"Br2xjsUzaYcS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761412352470,"user_tz":360,"elapsed":6016,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"87c4fe59-d520-4b66-c6b5-1016a102c7df"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping cudf-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping cuml-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping cugraph-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping dask-cudf-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping dask-cuda as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping rapids-dask-dependency as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping distributed-ucxx-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping ucx-py-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping rmm-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping cuvs-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping cupy-cuda12x as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping raft-dask-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping nx-cugraph-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping pylibcugraph-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping pylibraft-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping ucxx-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping tensorflow-text as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping tensorflow-decision-forests as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping keras-hub as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping tensorflow-hub as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping crepe as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Remove RAPIDS & TF families that cause dependency conflicts in Colab\n","!pip -q uninstall -y \\\n","  cudf-cu12 numba cuml-cu12 cugraph-cu12 dask-cudf-cu12 dask-cuda rapids-dask-dependency \\\n","  distributed-ucxx-cu12 ucx-py-cu12 rmm-cu12 cudf-cu12 cuvs-cu12 cupy-cuda12x raft-dask-cu12 nx-cugraph-cu12 \\\n","  pylibcugraph-cu12 pylibraft-cu12 ucxx-cu12 \\\n","  tensorflow tensorflow-text tensorflow-decision-forests tf-keras keras keras-hub tensorflow-hub \\\n","  ddsp crepe || true\n","\n","# Fresh packaging toolchain\n","!pip -q install -U pip setuptools wheel build jedi"]},{"cell_type":"code","source":["# Fresh NumPy/SciPy\n","!pip -q install --no-cache-dir --force-reinstall \"numpy==2.1.3\" \"scipy==1.14.1\"\n","\n","# TensorFlow stack that works on Py3.12 and satisfies DDSP/TFP imports\n","!pip -q install -U \"tensorflow==2.20.0\" \"tf-keras==2.20.0\" \"tensorflow-probability==0.25.0\"\n","\n","# Silence CPU runtimes warning if present\n","!pip -q uninstall -y jax-cuda12-plugin -q || true\n","\n","# numba compatible with NumPy 2.1.x (needed by librosa/resampy/etc.)\n","!pip -q install -U \"numba==0.62.0\"\n","\n","# Audio + utils\n","!pip -q install -U librosa soundfile absl-py\n","\n","# JAX + ecosystem\n","!pip -q install -U \"jax[cpu]>=0.4.28\" \"flax>=0.8.2\" \"optax>=0.2.2\" chex orbax-checkpoint gin-config clu\n","\n","\n","# Install DDSP source without its pinned (outdated) requirements\n","!pip -q install --no-deps \"git+https://github.com/magenta/ddsp@main#egg=ddsp\"\n","\n","# f0 extractor (replacement for CREPE)\n","!pip -q install -U torch torchcrepe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"mTObj8rKtFqZ","executionInfo":{"status":"ok","timestamp":1761412436977,"user_tz":360,"elapsed":72011,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"775408c0-b580-4441-a3ff-fba63b365c17"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","resampy 0.4.3 requires numba>=0.53, which is not installed.\n","dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n","dopamine-rl 4.1.2 requires tf-keras>=2.18.0, which is not installed.\n","stumpy 1.13.0 requires numba>=0.57.1, which is not installed.\n","umap-learn 0.5.9.post2 requires numba>=0.51.2, which is not installed.\n","librosa 0.11.0 requires numba>=0.51.0, which is not installed.\n","pynndescent 0.5.13 requires numba>=0.51.2, which is not installed.\n","shap 0.49.1 requires numba>=0.54, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'tf-keras' candidate (version 2.20.0 at https://files.pythonhosted.org/packages/50/9b/136dcabd535d98ce3729f6520fdfc6c8949e6209a7a847b067e114216deb/tf_keras-2.20.0-py3-none-any.whl (from https://pypi.org/simple/tf-keras/) (requires-python:>=3.9))\n","Reason for being yanked: <none given>\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping jax-cuda12-plugin as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for ddsp (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["import os\n","os.environ.setdefault(\"TF_GPU_ALLOCATOR\", \"cuda_malloc_async\")  # helps fragmentation\n","\n","import tensorflow as tf\n","# Let TF allocate GPU memory gradually\n","for gpu in tf.config.list_physical_devices(\"GPU\"):\n","    try:\n","        tf.config.experimental.set_memory_growth(gpu, True)\n","    except Exception as e:\n","        print(\"Could not set memory growth:\", e)\n","\n","# Mixed precision halves activation memory on GPU\n","from tensorflow.keras import mixed_precision\n","mixed_precision.set_global_policy(\"mixed_float16\")\n","\n","print(\"Policy:\", mixed_precision.global_policy())"],"metadata":{"id":"nY5kJIXDux0f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761412456295,"user_tz":360,"elapsed":7051,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"cf04a4f4-14e5-45ac-e837-0a27d87cb6bd"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Policy: <DTypePolicy \"mixed_float16\">\n"]}]},{"cell_type":"code","source":["# Provide a tiny 'crepe' module so ddsp.losses can import; we won't call it.\n","import sys, types\n","_crepe = types.ModuleType(\"crepe\")\n","def _predict_stub(*args, **kwargs):\n","    raise RuntimeError(\"ddsp.losses tried to call crepe.predict; use torchcrepe for f0 instead.\")\n","_crepe.predict = _predict_stub\n","sys.modules[\"crepe\"] = _crepe\n","\n","# Smoke test\n","import numpy as np, librosa, soundfile, torch, torchcrepe\n","import tensorflow_probability as tfp\n","import jax, flax, ddsp\n","\n","print(\"numpy:\", np.__version__)\n","print(\"TF / TFP:\", tf.__version__, \"/\", tfp.__version__)\n","print(\"jax / flax:\", jax.__version__, \"/\", flax.__version__)\n","print(\"ddsp:\", ddsp.__version__)"],"metadata":{"id":"DB52rvTPu1Dt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761412468681,"user_tz":360,"elapsed":11190,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"f5525a1d-0282-4b6f-cf69-ff43a764fb1d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["numpy: 2.1.3\n","TF / TFP: 2.20.0 / 0.25.0\n","jax / flax: 0.8.0 / 0.12.0\n","ddsp: 3.7.0\n"]}]},{"cell_type":"code","source":["#@title Mount & paths\n","from google.colab import drive\n","from pathlib import Path\n","import yaml, json, math, time\n","\n","drive.mount('/content/drive', force_remount=True)\n","\n","PROJECT_DIR = Path('/content/drive/MyDrive/ddsp-demucs')\n","CFG = yaml.safe_load(open(PROJECT_DIR / 'env' / 'config.yaml'))\n","\n","TFRECORDS_DIR = Path(CFG['paths']['tfrecords_dir'])\n","EXP_DIR = Path(CFG['paths']['exp_dir']) / 'run_ddsp_001'\n","EXP_DIR.mkdir(parents=True, exist_ok=True)\n","\n","print(\"TFRecords:\", TFRECORDS_DIR)\n","print(\"Exp:\", EXP_DIR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZD-Gt_uku3Tn","executionInfo":{"status":"ok","timestamp":1761412495669,"user_tz":360,"elapsed":20603,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"ac6fc6a6-7638-4910-cbfd-b201fb268989"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","TFRecords: /content/drive/MyDrive/ddsp-demucs/data/tfrecords\n","Exp: /content/drive/MyDrive/ddsp-demucs/exp/run_ddsp_001\n"]}]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"dBN89GuzxK7u"}},{"cell_type":"code","source":["#@title Training Files\n","# === Locate TFRecords & define train_files / val_files / compression ===\n","from pathlib import Path\n","import yaml\n","\n","# Guess your project root (adjust if needed)\n","PROJECT_DIR = Path(\"/content/drive/MyDrive/ddsp-demucs\")\n","\n","def find_tfrecords_dir():\n","    cfg_path = PROJECT_DIR / \"env\" / \"config.yaml\"\n","    if cfg_path.exists():\n","        try:\n","            CFG = yaml.safe_load(open(cfg_path))\n","            return Path(CFG[\"paths\"][\"tfrecords_dir\"])\n","        except Exception as e:\n","            print(\"Config read failed, falling back to default:\", e)\n","    # Fallback used earlier in this notebook\n","    return PROJECT_DIR / \"data\" / \"tfrecords\"\n","\n","TFRECORDS_DIR = find_tfrecords_dir()\n","\n","def pick_split_dir(base, *names):\n","    for name in names:\n","        d = base / name\n","        if d.exists():\n","            return d\n","    return None\n","\n","train_dir = pick_split_dir(TFRECORDS_DIR, \"train\", \"training\")\n","val_dir   = pick_split_dir(TFRECORDS_DIR, \"val\", \"valid\", \"validation\", \"dev\")\n","\n","def list_shards(d):\n","    if d is None: return []\n","    patterns = [\"*.tfrecord\", \"*.tfrecords\", \"*.tfrecord.gz\", \"*.tfrecords.gz\"]\n","    files = []\n","    for pat in patterns:\n","        files += sorted(str(p) for p in d.glob(pat))\n","    return files\n","\n","train_files = list_shards(train_dir)\n","val_files   = list_shards(val_dir)\n","\n","def infer_compression(files_a, files_b):\n","    files = files_a if len(files_a) else files_b\n","    return \"GZIP\" if any(f.endswith(\".gz\") for f in files) else \"\"\n","\n","compression = infer_compression(train_files, val_files)\n","\n","print(\"TFRECORDS_DIR:\", TFRECORDS_DIR)\n","print(\"train_dir:\", train_dir)\n","print(\"val_dir:\", val_dir)\n","print(f\"Found {len(train_files)} train shards, {len(val_files)} val shards, compression='{compression}'\")\n","if train_files:\n","    print(\"Example train shard:\", train_files[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sPyYVafBuSC_","executionInfo":{"status":"ok","timestamp":1761413591921,"user_tz":360,"elapsed":732,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"3dbc7a44-ca0d-430b-ae53-ccb0e14c1647"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["TFRECORDS_DIR: /content/drive/MyDrive/ddsp-demucs/data/tfrecords\n","train_dir: /content/drive/MyDrive/ddsp-demucs/data/tfrecords/train\n","val_dir: /content/drive/MyDrive/ddsp-demucs/data/tfrecords/val\n","Found 14 train shards, 4 val shards, compression=''\n","Example train shard: /content/drive/MyDrive/ddsp-demucs/data/tfrecords/train/train-00000.tfrecord\n"]}]},{"cell_type":"code","source":["#@title Torhcrepe-backed f0\n","# ==== Torchcrepe-backed f0 (fixed for tf.py_function) ====\n","import numpy as np\n","import tensorflow as tf\n","\n","\n","import tensorflow as tf, ddsp, numpy as np\n","\n","# Training-time globals (pick what you want)\n","SR         = 16000          # your model SR\n","FRAME_RATE = 250\n","WIN_S      = 4.0            # matches the TFRecord writer's BuildCfg.win_s\n","AUDIO_SAMPLES = int(SR * WIN_S)\n","TPRIME     = int(FRAME_RATE * WIN_S)\n","compression = globals().get(\"compression\", \"\")  # \"\" or \"GZIP\"\n","assert AUDIO_SAMPLES == 64000 and TPRIME == 1000\n","\n","# Loudness gate for voicing fallback\n","LOUD_GATE_DB = -60.0\n","\n","import ddsp\n","\n","FEATURE_SPEC = {\n","    \"audio/inputs\":      tf.io.FixedLenFeature([], tf.string),\n","    \"audio/targets\":     tf.io.FixedLenFeature([], tf.string),\n","    \"audio/sample_rate\": tf.io.FixedLenFeature([], tf.int64),\n","    \"audio/length\":      tf.io.FixedLenFeature([], tf.int64),\n","    \"meta/track\":        tf.io.FixedLenFeature([], tf.string),\n","    \"meta/source\":       tf.io.FixedLenFeature([], tf.string),\n","    \"meta/start_sec\":    tf.io.FixedLenFeature([], tf.float32),\n","    \"meta/end_sec\":      tf.io.FixedLenFeature([], tf.float32),\n","}\n","# ---- Log-mel from the INPUT (Demucs) ----\n","MEL_BINS = 64\n","\n","\n","def _interp_to_len(x, n):\n","    \"\"\"Linear resample 1D numpy array x to length n.\"\"\"\n","    if len(x) == n:\n","        return x.astype(np.float32, copy=False)\n","    xp = np.linspace(0.0, 1.0, num=len(x), dtype=np.float32)\n","    xq = np.linspace(0.0, 1.0, num=n,       dtype=np.float32)\n","    return np.interp(xq, xp, x).astype(np.float32)\n","\n","def _torchcrepe_f0_np(y_in,\n","                      sr=SR,\n","                      frame_rate=FRAME_RATE,\n","                      fmin=80.0, fmax=1000.0,\n","                      periodicity_thresh=0.45,\n","                      use_gpu=True,\n","                      model_size=\"full\"):\n","    \"\"\"NumPy in -> NumPy out. Returns f0[TPRIME] in Hz.\"\"\"\n","    # tf.py_function hands us an EagerTensor; convert safely to contiguous float32 np array\n","    y_np = np.asarray(y_in).astype(np.float32, copy=True)\n","    if y_np.ndim != 1:\n","        y_np = y_np.reshape(-1)\n","    if y_np.size == 0:\n","        return np.zeros((TPRIME,), dtype=np.float32)\n","\n","    import torch, torchcrepe\n","\n","    hop = int(round(sr / float(frame_rate)))\n","    device = 'cuda' if (use_gpu and torch.cuda.is_available()) else 'cpu'\n","\n","    # torchcrepe expects shape [B, T]\n","    x = torch.from_numpy(y_np).unsqueeze(0).to(device)\n","\n","    with torch.no_grad():\n","        f0, per = torchcrepe.predict(\n","            audio=x,\n","            sample_rate=sr,\n","            hop_length=hop,\n","            fmin=fmin,\n","            fmax=fmax,\n","            model=model_size,         # 'tiny' for speed, 'full' for quality\n","            batch_size=2048,\n","            device=device,\n","            return_periodicity=True\n","        )\n","        # Smooth for stability\n","        per = torchcrepe.filter.median(per, 3)\n","        per = torchcrepe.filter.mean(per, 3)\n","        f0  = torchcrepe.filter.median(f0, 3)\n","        f0  = torchcrepe.filter.mean(f0, 3)\n","\n","    f0  = f0.squeeze(0).detach().cpu().numpy().astype(np.float32, copy=False)\n","    per = per.squeeze(0).detach().cpu().numpy().astype(np.float32, copy=False)\n","\n","    # Periodicity mask: unvoiced -> 0 Hz\n","    f0[per < periodicity_thresh] = 0.0\n","\n","    # Ensure exactly TPRIME frames\n","    f0 = _interp_to_len(f0, TPRIME)\n","    return f0\n","\n","def _f0_from_torchcrepe_tf(y_1d,\n","                           fmin=90.0, fmax=600.0,   # tighter vocal range helps\n","                           periodicity_thresh=0.45,\n","                           model_size=\"full\"):\n","    \"\"\"TensorFlow wrapper: y_1d [S] -> f0 [TPRIME] float32 via torchcrepe.\"\"\"\n","    f0 = tf.py_function(\n","        func=lambda x: _torchcrepe_f0_np(\n","            x, sr=SR, frame_rate=FRAME_RATE,\n","            fmin=fmin, fmax=fmax,\n","            periodicity_thresh=periodicity_thresh,\n","            model_size=model_size\n","        ),\n","        inp=[y_1d],\n","        Tout=tf.float32,\n","    )\n","    # Fix the static shape for downstream layers\n","    f0 = tf.ensure_shape(f0, [TPRIME])\n","    return f0\n"],"metadata":{"id":"toB6_WJKxBDN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Parameters and Training Data\n","def _logmel_1xTprime(y_1d, n_fft=1024):\n","    hop = tf.cast(tf.math.round(SR / FRAME_RATE), tf.int32)\n","    S = tf.signal.stft(\n","        y_1d, frame_length=n_fft, frame_step=hop, fft_length=n_fft,\n","        window_fn=tf.signal.hann_window, pad_end=True\n","    )                               # [T, F]\n","    mag = tf.abs(S)\n","    mel_fb = tf.signal.linear_to_mel_weight_matrix(\n","        num_mel_bins=MEL_BINS,\n","        num_spectrogram_bins=n_fft // 2 + 1,\n","        sample_rate=SR,\n","        lower_edge_hertz=50.0,\n","        upper_edge_hertz=SR * 0.45,\n","    )                               # [F, M]\n","    mel = tf.matmul(mag, mel_fb)    # [T, M]\n","    mel = tf.math.log(mel + 1e-5)\n","    mel = tf.squeeze(ddsp.core.resample(mel[tf.newaxis, :, :], TPRIME), 0)  # [T', M]\n","    # per-sample normalize (helps training)\n","    m_mean = tf.reduce_mean(mel, axis=-1, keepdims=True)\n","    m_std  = tf.math.reduce_std(mel, axis=-1, keepdims=True) + 1e-5\n","    mel_n  = (mel - m_mean) / m_std\n","    return tf.ensure_shape(mel_n, [TPRIME, MEL_BINS])\n","\n","\n","def _pad_crop_1d(x, L):\n","    x = x[:L]\n","    pad = tf.maximum(0, L - tf.shape(x)[0])\n","    x = tf.pad(x, [[0, pad]])\n","    return tf.ensure_shape(x, [L])\n","\n","def _resample_to_sr(y, sr_in, sr_out=SR):\n","    y2 = y[tf.newaxis, :]\n","    rate = tf.cast(sr_out, tf.float32) / tf.cast(sr_in, tf.float32)\n","    n_out = tf.cast(tf.round(tf.cast(tf.shape(y2)[1], tf.float32) * rate), tf.int32)\n","    y2 = ddsp.core.resample(y2, n_out)\n","    return tf.squeeze(y2, 0)\n","\n","def _rms_loudness_db(y_1d):\n","    hop = tf.cast(tf.math.round(SR / FRAME_RATE), tf.int32)\n","    win = tf.maximum(hop * 2, 256)\n","    frames = tf.signal.frame(y_1d, frame_length=win, frame_step=hop, pad_end=True)\n","    rms = tf.sqrt(tf.reduce_mean(tf.square(frames), axis=-1) + 1e-12)\n","    ld_db = 20.0 * tf.math.log(rms + 1e-7) / tf.math.log(10.0)\n","    ld_db = tf.clip_by_value(ld_db, -120.0, 0.0)\n","    ld_db = ddsp.core.resample(ld_db[tf.newaxis, :], TPRIME)\n","    return tf.squeeze(ld_db, 0)\n","\n","def _parse_and_features(serialized):\n","    ex = tf.io.parse_single_example(serialized, FEATURE_SPEC)\n","    L  = tf.cast(ex[\"audio/length\"], tf.int32)\n","    sr = tf.cast(ex[\"audio/sample_rate\"], tf.int32)\n","\n","    # float32 decode (your TFRecords are float32)\n","    x_in  = tf.io.decode_raw(ex[\"audio/inputs\"],  tf.float32)[:L]\n","    y_tgt = tf.io.decode_raw(ex[\"audio/targets\"], tf.float32)[:L]\n","\n","    # resample to SR (16k for torchcrepe), crop/pad to WIN_S\n","    x_in  = _pad_crop_1d(_resample_to_sr(x_in,  sr, SR), AUDIO_SAMPLES)\n","    y_tgt = _pad_crop_1d(_resample_to_sr(y_tgt, sr, SR), AUDIO_SAMPLES)\n","\n","    # conditioning from INPUT (Demucs)\n","    ld_db = _rms_loudness_db(x_in)\n","    f0_hz = _f0_from_torchcrepe_tf(x_in, fmin=90.0, fmax=600.0, periodicity_thresh=0.40, model_size=\"tiny\")\n","\n","    # safety: mute f0 on very quiet frames\n","    f0_hz = tf.where(ld_db > -60.0, f0_hz, tf.zeros_like(f0_hz))\n","\n","\n","    mel = _logmel_1xTprime(x_in)  # [T', 64]\n","\n","    # features from INPUT (Demucs)\n","    mel_in = _logmel_1xTprime(x_in)                                  # [T', 64]\n","    f0_in  = _f0_from_torchcrepe_tf(x_in, fmin=90.0, fmax=600.0)\n","\n","    # features from TARGET (clean)  — cached once, reused every epoch\n","    mel_gt = _logmel_1xTprime(y_tgt)\n","    f0_gt  = _f0_from_torchcrepe_tf(y_tgt, fmin=90.0, fmax=600.0)\n","\n","    cond = {\n","        \"x_in\":        x_in,\n","        \"f0_in\":       f0_in,         # torchcrepe once\n","        # \"f0_gt\":     (omit for speed)\n","        \"loudness_db\": ld_db,\n","        \"mel_in\":      mel_in,        # cheap\n","        \"mel_gt\":      mel_gt,        # cheap\n","        \"track\":       ex[\"meta/track\"],\n","    }\n","    return cond, y_tgt\n","\n","def make_ds(files, compression=\"\", cache_path=None):\n","    ds = tf.data.TFRecordDataset(files, compression_type=compression)\n","    ds = ds.map(_parse_and_features, num_parallel_calls=1, deterministic=True)\n","    ds = ds.cache(str(cache_path) if cache_path else None)\n","    ds = ds.batch(1, drop_remainder=True).prefetch(1)\n","    return ds\n","\n","# Build sets\n","# train_ds = make_ds(train_files,  compression=compression)\n","# val_ds   = make_ds(val_files,    compression=compression)\n"],"metadata":{"id":"g-mJ5KSWyE8N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Model\n","# --- hard reset setup ---\n","import os, tensorflow as tf, tensorflow.keras as keras, ddsp\n","from tensorflow.keras import mixed_precision\n","\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=0\"   # no XLA while stabilizing\n","mixed_precision.set_global_policy(\"float32\")         # keep dtypes simple\n","\n","for gpu in tf.config.list_physical_devices(\"GPU\"):\n","    try:\n","        tf.config.experimental.set_memory_growth(gpu, True)\n","    except Exception:\n","        pass\n","tf.config.optimizer.set_jit(False)\n","\n","# --- tiny harmonic-only model (same as before) ---\n","from ddsp.synths import Harmonic, FilteredNoise\n","from ddsp.effects import Reverb\n","\n","N_HARMONICS   = 64\n","N_NOISE_BANDS = 65\n","MEL_BINS      = 64\n","LOUD_GATE_DB  = -60.0\n","MAX_HZ = 6000.0\n","\n","class DDSPDecoder(keras.Model):\n","    def __init__(self, rnn_units=256, mlp_units=(256,128),\n","                 tf_decay_steps=5000,\n","                 tau=0.5,                 # ↓ lower temperature\n","                 sine_warmup_steps=300,   # shorter warmup\n","                 **kw):\n","        super().__init__(**kw)\n","        self.tau = float(tau)\n","        self.sine_warmup_steps = int(sine_warmup_steps)\n","        self.tf_decay_steps = int(tf_decay_steps)\n","        self.global_step = tf.Variable(0, trainable=False, dtype=tf.int64)\n","\n","\n","\n","\n","        # Timbre encoder from mel\n","        self.mel_proj = keras.layers.Dense(128, activation='relu')\n","\n","        self.pre  = keras.layers.Dense(128, activation='relu')\n","        self.gru  = keras.layers.GRU(rnn_units, return_sequences=True)\n","        self.post = keras.Sequential([keras.layers.Dense(u, activation='relu') for u in mlp_units])\n","\n","        # Bias harmonic logits with a steeper 1/h prior\n","        decay_bias = -0.30 * np.arange(N_HARMONICS, dtype=np.float32)  # <- steeper\n","        self.amp_head   = keras.layers.Dense(1)\n","        self.harm_head  = keras.layers.Dense(N_HARMONICS,\n","                              bias_initializer=keras.initializers.Constant(decay_bias))\n","        self.noise_head = keras.layers.Dense(N_NOISE_BANDS)\n","\n","        # NEW: learnable harmonic roll-off factor α(t) ≥ 0\n","        self.roll_head  = keras.layers.Dense(1)  # predicts alpha(t)\n","        self.k_idx = tf.cast(tf.range(1, N_HARMONICS+1)[tf.newaxis, tf.newaxis, :], tf.float32)\n","\n","        self.harm  = ddsp.synths.Harmonic(sample_rate=SR, amp_resample_method='linear')\n","        self.noise = ddsp.synths.FilteredNoise(n_samples=AUDIO_SAMPLES,\n","                                               scale_fn=ddsp.core.exp_sigmoid,\n","                                               initial_bias=-12.0)\n","        self.reverb = ddsp.effects.Reverb(trainable=True)\n","\n","        # fixed 1/h tilt prior (broadcasted [1,1,H])\n","        self.tilt_log_b = tf.math.log(1.0 / tf.cast(tf.range(1, N_HARMONICS+1), tf.float32))[tf.newaxis, tf.newaxis, :]\n","\n","        # Start dry near zero (don’t just copy Demucs)\n","        self.dry_logit = tf.Variable(-6.0, trainable=True)  # sigmoid≈0.0025\n","\n","    def call(self, inputs, training=False):\n","\n","        training_b = tf.cast(tf.convert_to_tensor(training) if not isinstance(training, bool)\n","                     else tf.constant(training), tf.bool)\n","\n","        use_gt = tf.logical_and(training_b,\n","                        tf.less(self.global_step, tf.cast(self.tf_decay_steps, tf.int64)))\n","\n","        # f0: ALWAYS from input (no torchcrepe on target)\n","        if \"f0_in\" in inputs:\n","            f0_hz = tf.cast(inputs[\"f0_in\"], tf.float32)\n","        else:\n","            f0_hz = tf.cast(inputs[\"f0_hz\"], tf.float32)  # fallback\n","\n","        # mel: teacher forced (GT early, then Demucs)\n","        if (\"mel_gt\" in inputs) and (\"mel_in\" in inputs):\n","            mel = tf.cond(use_gt,\n","                          lambda: tf.cast(inputs[\"mel_gt\"], tf.float32),\n","                          lambda: tf.cast(inputs[\"mel_in\"], tf.float32))\n","        else:\n","            mel = tf.cast(inputs[\"mel\"], tf.float32)      # fallback\n","\n","        ld_db = tf.cast(inputs[\"loudness_db\"], tf.float32)\n","        x_in  = tf.cast(inputs[\"x_in\"], tf.float32)\n","\n","        m = self.mel_proj(mel)                               # [B,T’,128]\n","        scalars = tf.stack([f0_hz, ld_db], axis=-1)          # [B,T’,2]\n","        x = tf.concat([scalars, m], axis=-1)                 # [B,T’,130]\n","        x = self.pre(x); x = self.gru(x); x = self.post(x)\n","\n","        amp_raw     = ddsp.core.exp_sigmoid(self.amp_head(x))            # [B,T’,1]\n","        harm_logits = self.harm_head(x)                                   # [B,T’,H]\n","        alpha       = tf.nn.softplus(self.roll_head(x)) + 0.05            # α(t) ≥ 0.05\n","        roll        = tf.exp(-alpha * self.k_idx)                         # [B,T’,H], decays with k\n","        harm_pre    = harm_logits / self.tau + self.tilt_log_b + tf.math.log(roll + 1e-8)\n","        harm_dist   = tf.nn.softmax(harm_pre, axis=-1)                    # [B,T’,H]\n","\n","\n","        # cap by Nyquist for each frame so high harmonics vanish when f0 is high\n","        Hmax = tf.cast(tf.floor((SR * 0.5) / tf.maximum(f0_hz, 1e-6)), tf.int32)  # [B,T']\n","        mask = tf.sequence_mask(Hmax, maxlen=N_HARMONICS, dtype=tf.float32)       # [B,T',H]\n","        harm_dist = harm_dist * mask\n","        harm_dist = harm_dist / (tf.reduce_sum(harm_dist, axis=-1, keepdims=True) + 1e-8)\n","\n","\n","\n","        noise_mag   = ddsp.core.exp_sigmoid(self.noise_head(x))           # [B,T’,B]\n","\n","        ld_amp  = ddsp.core.db_to_amplitude(ld_db)                        # [B,T’]\n","        voicing = tf.cast(f0_hz > 0.0, tf.float32)\n","        voicing = tf.maximum(voicing, tf.cast(ld_db > LOUD_GATE_DB, tf.float32))\n","\n","        amp = (amp_raw + 1e-3) * (ld_amp[..., None] + 1e-4) * voicing[..., None]\n","        noise_mag = (noise_mag + 1e-3) * tf.maximum(ld_amp, 1e-4)[..., None]\n","        # even less noise on voiced frames\n","        noise_mag *= (0.95*(1.0 - voicing) + 0.15*voicing)[..., None]\n","\n","        # short warm-up: fundamental only\n","\n","        warmup_active = tf.less(self.global_step, tf.cast(self.sine_warmup_steps, tf.int64))\n","        do_warmup = tf.logical_and(training_b, warmup_active)\n","        def _fundamental_only():\n","            b = tf.shape(harm_dist)[0]; t = tf.shape(harm_dist)[1]\n","            return tf.one_hot(tf.zeros([b, t], tf.int32), N_HARMONICS)\n","        harm_dist = tf.cond(do_warmup, _fundamental_only, lambda: harm_dist)\n","\n","        amp       = tf.ensure_shape(amp,       [None, TPRIME, 1])\n","        harm_dist = tf.ensure_shape(harm_dist, [None, TPRIME, N_HARMONICS])\n","        noise_mag = tf.ensure_shape(noise_mag, [None, TPRIME, N_NOISE_BANDS])\n","\n","        f0_3d   = f0_hz[..., tf.newaxis]\n","        audio_h = self.harm(amplitudes=amp, harmonic_distribution=harm_dist, f0_hz=f0_3d)\n","        audio_n = self.noise(magnitudes=noise_mag)\n","\n","        synth = self.reverb(audio_h + audio_n)\n","        dry_g = tf.nn.sigmoid(self.dry_logit)\n","        return dry_g * x_in + (1.0 - dry_g) * synth\n","\n","from ddsp.losses import SpectralLoss\n","spec_loss = SpectralLoss(\n","    fft_sizes=(2048,1024,512,256,128,64),\n","    loss_type='L1',\n","    mag_weight=1.0,\n","    logmag_weight=1.0,\n","    delta_freq_weight=0.5,\n","    delta_time_weight=0.1,\n",")\n","\n","def mel_spec(y, n_fft=1024, hop=None):\n","    if hop is None:\n","        hop = int(round(SR / FRAME_RATE))\n","    S = tf.abs(tf.signal.stft(y, n_fft, hop, n_fft, window_fn=tf.signal.hann_window, pad_end=True))\n","    mel_fb = tf.signal.linear_to_mel_weight_matrix(MEL_BINS, n_fft//2+1, SR, 50.0, SR*0.45)\n","    M = tf.matmul(S, mel_fb)  # [B, Tm, M]\n","    return tf.math.log(M + 1e-5)\n","\n","def mel_l1(y_true, y_pred):\n","    Yt = mel_spec(y_true); Yp = mel_spec(y_pred)\n","    n = tf.minimum(tf.shape(Yt)[1], tf.shape(Yp)[1])\n","    return tf.reduce_mean(tf.abs(Yt[:, :n, :] - Yp[:, :n, :]))\n","\n","def spec_centroid(y, n_fft=1024, hop=None):\n","    if hop is None:\n","        hop = int(round(SR / FRAME_RATE))\n","    S = tf.abs(tf.signal.stft(y, n_fft, hop, n_fft, window_fn=tf.signal.hann_window, pad_end=True))  # [B,T,F]\n","    freqs = tf.linspace(0.0, tf.cast(SR, tf.float32)/2.0, n_fft//2+1)                                # [F]\n","    num = tf.reduce_sum(S * freqs[tf.newaxis, tf.newaxis, :], axis=-1)                               # [B,T]\n","    den = tf.reduce_sum(S + 1e-8, axis=-1)                                                           # [B,T]\n","    c   = num / (den + 1e-8)                                                                          # [B,T], Hz\n","    return tf.reduce_mean(c, axis=-1)                                                                 # [B]\n","\n","def centroid_l1(y_true, y_pred):\n","    ct = spec_centroid(y_true); cp = spec_centroid(y_pred)\n","    return tf.reduce_mean(tf.abs(ct - cp)) / (SR/2.0)  # normalize to [0,1]\n","\n","class DDSPTrainer(keras.Model):\n","    def __init__(self, net, mel_w=1.0, cent_w=0.05):\n","        super().__init__(); self.net = net\n","        self.mel_w, self.cent_w = mel_w, cent_w\n","        self.train_metric = keras.metrics.Mean(name=\"loss\")\n","        self.val_metric   = keras.metrics.Mean(name=\"val_loss\")\n","\n","    @property\n","    def metrics(self): return [self.train_metric, self.val_metric]\n","    def build(self, _=None): self.built = True\n","    def compile(self, optimizer): super().compile(); self.optimizer = optimizer\n","\n","    @tf.function\n","    def _loss(self, y_t, y_p):\n","        Ls = spec_loss(y_t, y_p)\n","        Lm = mel_l1(y_t, y_p)\n","        Lc = centroid_l1(y_t, y_p)\n","        return Ls + self.mel_w*Lm + self.cent_w*Lc\n","\n","    @tf.function\n","    def train_step(self, data):\n","        cond, target = data\n","        with tf.GradientTape() as tape:\n","            pred = self.net(cond, training=True)\n","            n = tf.minimum(tf.shape(pred)[1], tf.shape(target)[1])\n","            loss = self._loss(tf.cast(target[:, :n], tf.float32), tf.cast(pred[:, :n], tf.float32))\n","        grads = tape.gradient(loss, self.net.trainable_variables)\n","        self.optimizer.apply_gradients(zip(grads, self.net.trainable_variables))\n","        if hasattr(self.net, \"global_step\"): self.net.global_step.assign_add(1)\n","        self.train_metric.update_state(loss)\n","        return {\"loss\": self.train_metric.result()}\n","\n","    @tf.function\n","    def test_step(self, data):\n","        cond, target = data\n","        pred = self.net(cond, training=False)\n","        n = tf.minimum(tf.shape(pred)[1], tf.shape(target)[1])\n","        loss = self._loss(tf.cast(target[:, :n], tf.float32), tf.cast(pred[:, :n], tf.float32))\n","        self.val_metric.update_state(loss)\n","        return {\"loss\": self.val_metric.result()}"],"metadata":{"id":"sZJsyt2p0HxJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---- One-time setup (run once) ----\n","import numpy as np, torch, torchcrepe, tensorflow as tf\n","torch.set_num_threads(1)  # avoid CPU thread thrash\n","\n","def _torchcrepe_f0_np(y_np, sr, hop_length, fmin, fmax, periodicity_thresh, model_size):\n","    # y_np: 1D float32\n","    y_np = np.ascontiguousarray(y_np.astype(np.float32), dtype=np.float32)\n","    x = torch.from_numpy(y_np[None, None, :])  # [B=1, C=1, T], CPU\n","    with torch.no_grad():\n","        f0, pd = torchcrepe.predict(\n","            x, int(sr), int(hop_length),\n","            float(fmin), float(fmax),\n","            model=str(model_size),           # \"tiny\" or \"full\"\n","            batch_size=1024,\n","            device=\"cpu\",                    # keep crepe on CPU\n","            return_periodicity=True,\n","        )\n","    f0 = f0.squeeze(0).squeeze(0).cpu().numpy()\n","    pd = pd.squeeze(0).squeeze(0).cpu().numpy()\n","    f0[pd < float(periodicity_thresh)] = 0.0  # simple V/UV mask\n","    return f0.astype(np.float32, copy=False)\n","\n","def _f0_from_torchcrepe_tf(\n","    y_1d,\n","    fmin=90.0,\n","    fmax=600.0,\n","    hop_length=512,\n","    periodicity_thresh=0.40,\n","    model_size=\"tiny\",\n","    # SR and TPRIME should be defined globally in your notebook\n","):\n","    f0 = tf.numpy_function(\n","        _torchcrepe_f0_np,\n","        [y_1d,\n","         tf.constant(SR, tf.int32),\n","         tf.constant(hop_length, tf.int32),\n","         tf.constant(fmin, tf.float32),\n","         tf.constant(fmax, tf.float32),\n","         tf.constant(periodicity_thresh, tf.float32),\n","         tf.constant(model_size, tf.string)],\n","        Tout=tf.float32,\n","    )\n","    f0 = tf.ensure_shape(tf.reshape(f0, [-1]), [None])            # [Tf0]\n","    f0 = ddsp.core.resample(f0[tf.newaxis, :], TPRIME)            # [1, T']\n","    return tf.ensure_shape(tf.squeeze(f0, 0), [TPRIME])           # [T']\n"],"metadata":{"id":"hlWu4AC3m-jb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path\n","\n","def make_cached_slice(files, K=400, compression=\"\", cache_path=None):\n","    ds = tf.data.TFRecordDataset(files, compression_type=compression)\n","    ds = ds.map(_parse_and_features, num_parallel_calls=1, deterministic=True)\n","    ds = ds.take(K)\n","    ds = ds.cache(str(cache_path) if cache_path else None)   # RAM/disk\n","    ds = ds.shuffle(K, reshuffle_each_iteration=True).repeat()\n","    ds = ds.batch(1, drop_remainder=True).prefetch(1)\n","    return ds\n","\n","# Local (fast) cache paths — avoid Google Drive paths here\n","train_run = make_cached_slice(train_files, K=400, compression=compression, cache_path=\"/content/cache/train_slice\")\n","val_run   = make_cached_slice(val_files,   K=120, compression=compression, cache_path=\"/content/cache/val_slice\")\n"],"metadata":{"id":"4uqU32zHnGvy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run once\n","import numpy as np, torch, torchcrepe\n","\n","torch.set_num_threads(1)  # avoid CPU thread thrash\n","\n","def _torchcrepe_f0_np(y_np, sr, hop_length, fmin, fmax, periodicity_thresh, model_size):\n","    # Flatten to 1D, contiguous, float32\n","    y_np = np.asarray(y_np, dtype=np.float32).reshape(-1)\n","    y_np = np.ascontiguousarray(y_np)\n","    # torchcrepe wants [B, 1, T] on CPU\n","    x = torch.from_numpy(y_np[None, None, :])  # [1,1,T]\n","    with torch.no_grad():\n","        f0, pd = torchcrepe.predict(\n","            x, int(sr), int(hop_length),\n","            float(fmin), float(fmax),\n","            model=str(model_size),          # \"tiny\" or \"full\"\n","            batch_size=1024,\n","            device=\"cpu\",\n","            return_periodicity=True,\n","        )\n","    f0 = f0.squeeze().cpu().numpy()\n","    pd = pd.squeeze().cpu().numpy()\n","    f0[pd < float(periodicity_thresh)] = 0.0\n","    return f0.astype(np.float32, copy=False)\n"],"metadata":{"id":"3XvA7txvqaTD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf, ddsp, numpy as np\n","\n","# === utils ===\n","def _to_Tprime(vec_1d, TPRIME):\n","    \"\"\"vec_1d: [T*] → [TPRIME] via linear resample.\"\"\"\n","    vec_1d = tf.reshape(tf.cast(vec_1d, tf.float32), [-1])\n","    out = ddsp.core.resample(vec_1d[tf.newaxis, :], int(TPRIME))  # [1, TPRIME]\n","    return tf.squeeze(out, 0)\n","\n","def _pad_crop_1d(x, length):\n","    x = tf.reshape(x, [-1])\n","    x = x[:length]\n","    pad = tf.maximum(0, length - tf.shape(x)[0])\n","    x = tf.pad(x, [[0, pad]])\n","    x.set_shape([length])\n","    return x\n","\n","def _resample_to_sr(x, sr_in, sr_out):\n","    x = tf.reshape(x, [-1])\n","    if sr_in == sr_out:\n","        return x\n","    ratio = tf.cast(sr_out, tf.float32) / tf.cast(sr_in, tf.float32)\n","    new_len = tf.cast(tf.round(tf.cast(tf.shape(x)[0], tf.float32) * ratio), tf.int32)\n","    return tf.reshape(ddsp.core.resample(x[tf.newaxis, :], new_len)[0], [-1])\n","\n","def _rms_loudness_db(x, TPRIME, eps=1e-8):\n","    # rough per-frame loudness, then resample to TPRIME\n","    x = tf.reshape(x, [1, -1])\n","    # pick a hop that gives ~TPRIME frames\n","    hop = tf.maximum(1, tf.shape(x)[1] // int(TPRIME))\n","    win = tf.maximum(256, hop * 2)\n","    stft = tf.signal.stft(x, frame_length=win, frame_step=hop,\n","                          window_fn=tf.signal.hann_window, pad_end=True)\n","    mag = tf.abs(stft)  # [1, T*, F]\n","    rms = tf.sqrt(tf.reduce_mean(tf.square(mag), axis=-1) + eps)  # [1, T*]\n","    ld  = 20.0 * tf.math.log(rms + eps) / tf.math.log(10.0)\n","    ld  = tf.squeeze(ld, 0)              # [T*]\n","    return _to_Tprime(ld, TPRIME)        # [TPRIME]\n","\n","def _logmel_1xTprime(x, SR, TPRIME, n_fft=1024, mel_bins=64):\n","    x = tf.reshape(x, [1, -1])\n","    hop = tf.maximum(1, tf.shape(x)[1] // int(TPRIME))\n","    S = tf.abs(tf.signal.stft(x, frame_length=n_fft, frame_step=hop,\n","                              window_fn=tf.signal.hann_window, pad_end=True))  # [1,T*,F]\n","    mel_fb = tf.signal.linear_to_mel_weight_matrix(\n","        num_mel_bins=mel_bins,\n","        num_spectrogram_bins=n_fft//2 + 1,\n","        sample_rate=int(SR),\n","        lower_edge_hertz=50.0,\n","        upper_edge_hertz=float(SR) * 0.45,\n","    )\n","    M = tf.matmul(S, mel_fb)            # [1,T*,mel]\n","    M = tf.math.log(M + 1e-5)\n","    M = tf.squeeze(M, 0)                # [T*, mel]\n","    # resample along time to TPRIME\n","    M = tf.transpose(M, [1, 0])         # [mel, T*]\n","    M = ddsp.core.resample(M[tf.newaxis, ...], int(TPRIME))  # [1, mel, TPRIME]\n","    M = tf.squeeze(M, 0)                # [mel, TPRIME]\n","    return tf.transpose(M, [1, 0])      # [TPRIME, mel]\n"],"metadata":{"id":"M3jIpaSrqemg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set these to your globals\n","# SR = 22050\n","# AUDIO_SAMPLES = 64000\n","# TPRIME = 1000   # frames per 4 s at 250 Hz, etc.\n","\n","def _parse_no_f0(serialized):\n","    feats = {\n","        \"audio/inputs\":      tf.io.FixedLenFeature([], tf.string),\n","        \"audio/targets\":     tf.io.FixedLenFeature([], tf.string),\n","        \"audio/sample_rate\": tf.io.FixedLenFeature([], tf.int64),\n","        \"meta/track\":        tf.io.FixedLenFeature([], tf.string),\n","    }\n","    ex  = tf.io.parse_single_example(serialized, feats)\n","    xin = tf.io.decode_raw(ex[\"audio/inputs\"], tf.float32)\n","    ygt = tf.io.decode_raw(ex[\"audio/targets\"], tf.float32)\n","    sr  = tf.cast(ex[\"audio/sample_rate\"], tf.int32)\n","\n","    xin = _pad_crop_1d(_resample_to_sr(xin, sr, SR), AUDIO_SAMPLES)\n","    ygt = _pad_crop_1d(_resample_to_sr(ygt, sr, SR), AUDIO_SAMPLES)\n","\n","    ld      = _rms_loudness_db(xin, TPRIME)                       # [TPRIME]\n","    mel_in  = _logmel_1xTprime(xin, SR, TPRIME, n_fft=1024)       # [TPRIME, 64]\n","    mel_gt  = _logmel_1xTprime(ygt, SR, TPRIME, n_fft=1024)\n","\n","    cond = {\n","        \"x_in\":        xin,\n","        \"f0_in\":       tf.zeros([TPRIME], tf.float32),  # stub: no crepe here\n","        \"loudness_db\": ld,\n","        \"mel_in\":      mel_in,\n","        \"mel_gt\":      mel_gt,\n","        \"track\":       ex[\"meta/track\"],\n","    }\n","    return cond, ygt\n"],"metadata":{"id":"J3obaoD1rPhy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time, tensorflow as tf\n","t0 = time.time()\n","_ = next(iter(tf.data.TFRecordDataset(train_files).map(_parse_no_f0).take(1)))\n","print(\"parse(no f0):\", time.time() - t0, \"s\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8E3QPauDqfxh","executionInfo":{"status":"ok","timestamp":1761015079599,"user_tz":360,"elapsed":1011,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"a0168e95-21ac-4a92-ac15-228eaccfda0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["parse(no f0): 1.0155503749847412 s\n"]}]},{"cell_type":"code","source":["import time\n","\n","# A) TFRecord I/O only\n","t0=time.time(); _ = next(iter(tf.data.TFRecordDataset(train_files).take(1))); print(\"I/O:\", time.time()-t0, \"s\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-2BbpBxvo87u","executionInfo":{"status":"ok","timestamp":1761014441272,"user_tz":360,"elapsed":27,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"4d8f0c4b-857b-4523-a62e-83164b8ec5d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I/O: 0.027957677841186523 s\n"]}]},{"cell_type":"code","source":["# B) Parse WITHOUT f0 (temporarily stub f0 to zeros to test)\n","def _parse_no_f0(rec):\n","    cond, y = _parse_and_features(rec)  # if your function fuses both, duplicate and remove the f0 call\n","    cond[\"f0_in\"] = tf.zeros([TPRIME], tf.float32)  # stub\n","    return cond, y\n","t0=time.time(); _ = next(iter(tf.data.TFRecordDataset(train_files).map(_parse_no_f0).take(1))); print(\"parse(no f0):\", time.time()-t0, \"s\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"59cBm7Mto_Kl","executionInfo":{"status":"error","timestamp":1761014456642,"user_tz":360,"elapsed":2367,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"fe9a5445-c9a4-4b07-ca20-96321684cae1"},"execution_count":null,"outputs":[{"output_type":"error","ename":"UnknownError","evalue":"{{function_node __wrapped__IteratorGetNext_output_types_7_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to MapDataset:26 transformation with iterator: Iterator::Root::Prefetch::FiniteTake::Map: RuntimeError: Expected 3D or 4D (batch mode) tensor with possibly 0 batch size and other non-zero dimensions for input, but got: [1, 1, 1, 1, 65024]\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/tmp/ipython-input-1094770658.py\", line 10, in _torchcrepe_f0_np\n    f0, pd = torchcrepe.predict(\n             ^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/torchcrepe/core.py\", line 117, in predict\n    for frames in generator:\n                  ^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/torchcrepe/core.py\", line 682, in preprocess\n    frames = torch.nn.functional.unfold(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 5611, in unfold\n    return torch._C._nn.im2col(\n           ^^^^^^^^^^^^^^^^^^^^\n\nRuntimeError: Expected 3D or 4D (batch mode) tensor with possibly 0 batch size and other non-zero dimensions for input, but got: [1, 1, 1, 1, 65024]\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3934032361.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcond\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"f0_in\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTPRIME\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# stub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mt0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_parse_no_f0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"parse(no f0):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    777\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3084\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3086\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3087\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6025\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6026\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6027\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnknownError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_7_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to MapDataset:26 transformation with iterator: Iterator::Root::Prefetch::FiniteTake::Map: RuntimeError: Expected 3D or 4D (batch mode) tensor with possibly 0 batch size and other non-zero dimensions for input, but got: [1, 1, 1, 1, 65024]\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/tmp/ipython-input-1094770658.py\", line 10, in _torchcrepe_f0_np\n    f0, pd = torchcrepe.predict(\n             ^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/torchcrepe/core.py\", line 117, in predict\n    for frames in generator:\n                  ^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/torchcrepe/core.py\", line 682, in preprocess\n    frames = torch.nn.functional.unfold(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 5611, in unfold\n    return torch._C._nn.im2col(\n           ^^^^^^^^^^^^^^^^^^^^\n\nRuntimeError: Expected 3D or 4D (batch mode) tensor with possibly 0 batch size and other non-zero dimensions for input, but got: [1, 1, 1, 1, 65024]\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"cx46QjDCpCNk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Building the trainer\n","model   = DDSPDecoder()\n","trainer = DDSPTrainer(model, mel_w=1.0, cent_w=0.05)\n","trainer.compile(optimizer=keras.optimizers.Adam(1e-3))\n","\n","dummy = {\n","  \"f0_hz\":       tf.zeros([1, TPRIME], tf.float32),\n","  \"loudness_db\": tf.ones([1, TPRIME], tf.float32) * -40.0,\n","  \"mel\":         tf.zeros([1, TPRIME, MEL_BINS], tf.float32),\n","  \"x_in\":        tf.zeros([1, AUDIO_SAMPLES], tf.float32),\n","}\n","_ = model(dummy, training=False)\n","trainer.build(None)\n","\n","\n","# Callbacks\n","from pathlib import Path\n","CKPT_DIR = Path(\"/content/ckpt\"); CKPT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath=str(CKPT_DIR / \"ddsp.weights.h5\"),\n","        save_weights_only=True,\n","        monitor=\"val_loss\",    # now available\n","        mode=\"min\",\n","        save_best_only=True,\n","    ),\n","    keras.callbacks.EarlyStopping(\n","        monitor=\"val_loss\",\n","        mode=\"min\",\n","        patience=5,\n","        restore_best_weights=True,\n","    ),\n","]\n","\n","from tensorflow.data import experimental as tfd\n","\n","def make_cached_slice(files, K=1000, compression=\"\", cache_path=None):\n","    base = tf.data.TFRecordDataset(files, compression_type=compression)\n","    base = base.map(_parse_and_features, num_parallel_calls=1, deterministic=True)\n","    if cache_path is None:\n","        base = base.take(K).cache()                         # RAM\n","    else:\n","        base = base.take(K).cache(str(cache_path))          # disk\n","    # Important: shuffle *after* caching and use K as buffer to permute the slice\n","    base = base.shuffle(K, reshuffle_each_iteration=True)\n","    base = base.repeat()                                    # endless\n","    base = base.batch(1, drop_remainder=True).prefetch(1)\n","    return base\n","\n","# Use the slice for speed while you iterate on the model:\n","TRAIN_STEPS = 400\n","VAL_STEPS   = 80\n","\n","train_ds = make_ds(train_files, compression=compression, cache_path=\"/content/cache/train\")\n","val_ds   = make_ds(val_files,   compression=compression, cache_path=\"/content/cache/val\")\n","train_run = make_cached_slice(train_files, K=400, compression=compression, cache_path=None)\n","val_run   = make_cached_slice(val_files,   K=120, compression=compression, cache_path=None)\n","\n","# train_run = make_cached_slice(train_files, K=400, compression=compression)\n","# val_run   = make_cached_slice(val_files,   K=120,  compression=compression)"],"metadata":{"id":"HDRLoAqC1Ozn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%time _ = next(iter(train_run.take(1)))"],"metadata":{"id":"RzJZQPmMkDsM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Fitting\n","\n","history = trainer.fit(\n","    train_run,\n","    validation_data=val_run,\n","    epochs=3,\n","    steps_per_epoch=TRAIN_STEPS,\n","    validation_steps=VAL_STEPS,\n","    callbacks=callbacks,\n","    verbose=1,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6RC6Cl2r5nuY","outputId":"ef2ddac3-c602-4cd8-cff7-5041711dd8fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n"]}]},{"cell_type":"code","source":["#@title Objective Evaluation\n","import numpy as np\n","from IPython.display import Audio, display\n","\n","def si_sdr(ref, est):\n","    ref = ref - np.mean(ref); est = est - np.mean(est)\n","    a = np.dot(est, ref) / (np.dot(ref, ref) + 1e-12)\n","    e_true = a * ref; e_res = est - e_true\n","    return 10*np.log10((np.sum(e_true**2)+1e-12)/(np.sum(e_res**2)+1e-12))\n","\n","def spec_conv(a, b, n_fft=1024, hop=256):\n","    A = np.abs(tf.signal.stft(a, n_fft, hop).numpy())\n","    B = np.abs(tf.signal.stft(b, n_fft, hop).numpy())\n","    return np.linalg.norm(A-B) / (np.linalg.norm(A)+1e-12)\n","\n","sdrs, scs = [], []\n","for k, (cond, tgt) in enumerate(val_ds.take(16)):\n","    pred = model({\n","        \"f0_hz\":       cond[\"f0_hz\"],\n","        \"loudness_db\": cond[\"loudness_db\"],\n","        \"mel\":         cond[\"mel\"],\n","        \"x_in\":        cond[\"x_in\"],\n","    }, training=False)\n","\n","    y = tgt[0].numpy().astype(np.float32)\n","    p = pred[0].numpy().astype(np.float32)\n","    n = min(len(y), len(p)); y, p = y[:n], p[:n]\n","    sdrs.append(si_sdr(y, p))\n","    scs.append(spec_conv(y, p))\n","print(f\"Val SI-SDR median: {np.median(sdrs):.2f} dB\")\n","print(f\"Val SpectralConv median: {np.median(scs):.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IVtutvWH5h-r","executionInfo":{"status":"ok","timestamp":1759603397300,"user_tz":360,"elapsed":10790,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"180a2ed7-bd12-442d-c96d-7869d4d71466"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Val SI-SDR median: -29.94 dB\n","Val SpectralConv median: 1.308\n"]}]},{"cell_type":"code","source":["from IPython.display import Audio, display\n","import numpy as np\n","\n","def play_idx(ds, idx, model, sr=SR):\n","    # get the idx-th item\n","    for i, (cond, tgt) in enumerate(ds.skip(idx).take(1)):\n","        pred = model({\n","          \"f0_hz\": cond[\"f0_hz\"],\n","          \"loudness_db\": cond[\"loudness_db\"],\n","          \"mel\": cond[\"mel\"],\n","          \"x_in\": cond[\"x_in\"],\n","        }, training=False)\n","        y = tgt[0].numpy().astype(np.float32)\n","        p = pred[0].numpy().astype(np.float32)\n","        display(Audio(y, rate=sr))\n","        display(Audio(p, rate=sr))\n","        break\n","\n","play_idx(val_ds, idx=12, model=model)     # specific"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"StCAKbjFiOca","executionInfo":{"status":"error","timestamp":1759683419388,"user_tz":360,"elapsed":27,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"4f747611-5b4c-4054-9b8c-b6c1adef6f97"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'SR' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4147990834.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mplay_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# get the idx-th item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'SR' is not defined"]}]}]}