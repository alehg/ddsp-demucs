{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOllWXMs1fu0a00VeXCZZX0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TVFxuhaSkyIv","executionInfo":{"status":"ok","timestamp":1758482671206,"user_tz":360,"elapsed":2213,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"3f13d209-8839-457a-8f68-209df880f558"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Project: /content/drive/MyDrive/ddsp-demucs\n","Stems: /content/drive/MyDrive/ddsp-demucs/data/stems/demucs_htdemucs44k\n","Features: /content/drive/MyDrive/ddsp-demucs/data/features\n","TFRecords out: /content/drive/MyDrive/ddsp-demucs/data/tfrecords\n","MUSDB root: /content/drive/MyDrive/ddsp-demucs/data/musdb18hq\n"]}],"source":["#@title Mount Drive & load config\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","from pathlib import Path\n","import yaml, json\n","\n","PROJECT_DIR = Path('/content/drive/MyDrive/ddsp-demucs')\n","CFG = yaml.safe_load(open(PROJECT_DIR / 'env' / 'config.yaml'))\n","\n","STEMS_DIR      = Path(CFG['paths']['stems_dir'])        # e.g., data/stems/demucs_htdemucs44k\n","FEATURES_DIR   = Path(CFG['paths']['features_dir'])     # e.g., data/features\n","TFRECORDS_DIR  = Path(CFG['paths']['tfrecords_dir'])    # e.g., data/tfrecords\n","TFRECORDS_DIR.mkdir(parents=True, exist_ok=True)\n","\n","MUSDB_ROOT = Path(CFG['dataset']['root'])               # symlink to musdb18_hq/\n","print(\"Project:\", PROJECT_DIR)\n","print(\"Stems:\", STEMS_DIR)\n","print(\"Features:\", FEATURES_DIR)\n","print(\"TFRecords out:\", TFRECORDS_DIR)\n","print(\"MUSDB root:\", MUSDB_ROOT)"]},{"cell_type":"code","source":["#@title TF setup (Lite 2.20) — uninstall extras that pin TF 2.19\n","import sys, subprocess, re, os\n","\n","def sh(cmd):\n","    print(\">\", cmd)\n","    return subprocess.run(cmd, shell=True, check=False, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT).stdout\n","\n","# Remove extras that force TF 2.19\n","print(sh(\"pip -q uninstall -y tensorflow-decision-forests tensorflow-text tf-keras\"))\n","\n","# Install/confirm TF 2.20\n","print(sh('pip -q install -U \"tensorflow==2.20.0\"'))\n","\n","# Verify and hard-restart to load correct TF binary cleanly\n","import tensorflow as tf\n","print(\"TF version now:\", tf.__version__)\n","# Force a clean restart so the loaded TF libs match the just-installed wheel\n","import os; os.kill(os.getpid(), 9)\n"],"metadata":{"id":"M1qghkS_uH4W","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ff65d9d2-374c-4c32-de1e-57018599a74d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["> pip -q uninstall -y tensorflow-decision-forests tensorflow-text tf-keras\n","\n","> pip -q install -U \"tensorflow==2.20.0\"\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 620.7/620.7 MB 2.1 MB/s eta 0:00:00\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 112.5 MB/s eta 0:00:00\n","ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","dopamine-rl 4.1.2 requires tf-keras>=2.18.0, which is not installed.\n","\n"]}]},{"cell_type":"code","source":["#@title Minimal deps after TF setup\n","!pip -q install musdb stempeg soundfile librosa tqdm -U\n","\n","import tensorflow as tf\n","import numpy as np, pandas as pd, soundfile as sf, librosa, musdb\n","from tqdm import tqdm\n","from dataclasses import dataclass\n","from pathlib import Path\n","\n","print(\"TF:\", tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"II2G7e8hrlpl","executionInfo":{"status":"ok","timestamp":1758482651541,"user_tz":360,"elapsed":8673,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"132c5890-c18e-45d7-9cea-22800c4f8015"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/963.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m962.6/963.0 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.0/963.0 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hTF: 2.20.0\n"]}]},{"cell_type":"code","source":["#@title Configure TFRecord building\n","@dataclass\n","class BuildCfg:\n","    # choose which accepted list to consume\n","    accepted_csv: Path = FEATURES_DIR / \"accepted_segments_quick.csv\"   # or \"accepted_segments_quota_detail.csv\"\n","    # final training SR\n","    train_sr: int = 22050\n","    # segment windowing inside each accepted region (creates many examples)\n","    win_s: float = 4.0\n","    hop_s: float = 1.0\n","    # sharding\n","    examples_per_shard: int = 512\n","    # split strategy: use MUSDB split (train/test) and within train make val split\n","    # val split (by track) ratio:\n","    val_ratio: float = 0.1\n","    # sanity: min voiced seconds per window (skip near-silence windows)\n","    min_rms_db: float = -50.0  # skip if loudness lower than this (approximate)\n","\n","BC = BuildCfg()\n","print(\"Using accepted segments from:\", BC.accepted_csv)"],"metadata":{"id":"UK8xr9wdtqXT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758482676959,"user_tz":360,"elapsed":14,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"be5e9e24-a9e2-4e14-fb2d-8a2430377a3f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Using accepted segments from: /content/drive/MyDrive/ddsp-demucs/data/features/accepted_segments_quick.csv\n"]}]},{"cell_type":"code","source":["#@title Load accepted segments & MUSDB track map\n","# accepted segments CSV must contain: track,start_s,end_s,mono_fraction,segment_pass\n","segs = pd.read_csv(BC.accepted_csv)\n","assert len(segs), f\"No segments in {BC.accepted_csv}\"\n","segs = segs[segs.segment_pass == True].copy()\n","segs[\"dur_s\"] = segs[\"end_s\"] - segs[\"start_s\"]\n","segs = segs[segs[\"dur_s\"] > 0.1]\n","print(\"Accepted segments:\", len(segs), \"| Unique tracks:\", segs.track.nunique())\n","\n","# MUSDB map: name -> (subset, rate, paths)\n","db = musdb.DB(root=str(MUSDB_ROOT), subsets=['train','test'], is_wav=True)\n","name2track = {t.name: t for t in db.tracks}\n","subset_map = {t.name: t.subset for t in db.tracks}\n","print(\"MUSDB tracks seen:\", len(name2track))\n","\n","# Verify stems folders exist for all\n","missing = [t for t in segs.track.unique() if not (STEMS_DIR / t / \"vocals.mono.wav\").exists()]\n","if missing:\n","    print(\"⚠️ Missing Demucs mono for tracks:\", missing[:5], \"... total\", len(missing))\n","    segs = segs[~segs.track.isin(missing)]\n","    print(\"Filtered to:\", len(segs), \"segments\")\n"],"metadata":{"id":"o-l0fccotzkz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758482840446,"user_tz":360,"elapsed":153463,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"089b8bd7-2f7a-46fd-8ad2-3a14908755d5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Accepted segments: 6361 | Unique tracks: 149\n","MUSDB tracks seen: 150\n"]}]},{"cell_type":"code","source":["#@title Helpers (audio IO, slicing, TF Example)\n","def read_wav_mono(path: Path):\n","    y, sr = sf.read(str(path), dtype='float32')\n","    if y.ndim > 1:\n","        y = y.mean(axis=1)\n","    return y, sr\n","\n","def slice_sec(x, sr, start_s, end_s):\n","    a = int(round(start_s * sr))\n","    b = int(round(end_s * sr))\n","    a = max(0, min(a, len(x)))\n","    b = max(0, min(b, len(x)))\n","    if b <= a:\n","        return np.zeros(1, dtype=np.float32)\n","    return x[a:b]\n","\n","def resample_if_needed(y, sr, tgt):\n","    if sr == tgt:\n","        return y, sr\n","    return librosa.resample(y, orig_sr=sr, target_sr=tgt), tgt\n","\n","def rms_db(x, eps=1e-8):\n","    rms = np.sqrt(np.mean(x.astype(np.float32)**2) + eps)\n","    return 20*np.log10(rms + eps)\n","\n","def make_example(x_in, x_tgt, sr, track, start_s, end_s, subset):\n","    # serialize float32 arrays as bytes\n","    x_in = np.asarray(x_in, dtype=np.float32)\n","    x_tgt = np.asarray(x_tgt, dtype=np.float32)\n","    feat = {\n","        \"audio/inputs\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[x_in.tobytes()])),\n","        \"audio/targets\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[x_tgt.tobytes()])),\n","        \"audio/sample_rate\": tf.train.Feature(int64_list=tf.train.Int64List(value=[int(sr)])),\n","        \"audio/length\": tf.train.Feature(int64_list=tf.train.Int64List(value=[int(len(x_in))])),\n","        \"meta/track\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[track.encode()])),\n","        \"meta/subset\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[subset.encode()])),\n","        \"meta/start_sec\": tf.train.Feature(float_list=tf.train.FloatList(value=[float(start_s)])),\n","        \"meta/end_sec\": tf.train.Feature(float_list=tf.train.FloatList(value=[float(end_s)])),\n","        \"meta/source\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[b\"demucs_htdemucs->ddsp\"]))\n","    }\n","    return tf.train.Example(features=tf.train.Features(feature=feat))\n"],"metadata":{"id":"bggiGdrkt3sm","executionInfo":{"status":"ok","timestamp":1758482840468,"user_tz":360,"elapsed":4,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#@title Build splits by track (stable)\n","rng = np.random.default_rng(1337)\n","\n","tracks = sorted(segs.track.unique())\n","# assign fixed split: MUSDB test -> \"test\"; MUSDB train -> split into train/val by track\n","val_candidates = [t for t in tracks if subset_map.get(t, \"train\") == \"train\"]\n","rng.shuffle(val_candidates)\n","n_val = int(round(len(val_candidates) * BC.val_ratio))\n","val_set = set(val_candidates[:n_val])\n","\n","def split_of(track):\n","    s = subset_map.get(track, \"train\")\n","    if s == \"test\":\n","        return \"test\"\n","    return \"val\" if track in val_set else \"train\"\n","\n","segs[\"split\"] = segs.track.map(split_of)\n","segs.split.value_counts()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":210},"id":"pPsuc48mwRKD","executionInfo":{"status":"ok","timestamp":1758483012979,"user_tz":360,"elapsed":55,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"9e6401b1-68f5-4f74-df74-8c3daaad7fb2"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["split\n","train    3628\n","test     2301\n","val       432\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>split</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>train</th>\n","      <td>3628</td>\n","    </tr>\n","    <tr>\n","      <th>test</th>\n","      <td>2301</td>\n","    </tr>\n","    <tr>\n","      <th>val</th>\n","      <td>432</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["#@title Write sharded TFRecords (train/val/test)\n","def shard_writer(prefix: Path, split: str, max_per_shard: int):\n","    prefix.mkdir(parents=True, exist_ok=True)\n","    count = 0\n","    shard_idx = 0\n","    writer = None\n","    def _open_new():\n","        nonlocal writer, shard_idx, count\n","        if writer is not None:\n","            writer.close()\n","        shard_path = prefix / f\"{split}-{shard_idx:05d}.tfrecord\"\n","        writer = tf.io.TFRecordWriter(str(shard_path))\n","        shard_idx += 1\n","        count = 0\n","    _open_new()\n","    def write(example):\n","        nonlocal writer, count\n","        writer.write(example.SerializeToString())\n","        count += 1\n","        if count >= max_per_shard:\n","            _open_new()\n","    def close():\n","        if writer is not None:\n","            writer.close()\n","    return write, close\n","\n","writers = {\n","    \"train\": shard_writer(TFRECORDS_DIR / \"train\", \"train\", BC.examples_per_shard),\n","    \"val\":   shard_writer(TFRECORDS_DIR / \"val\",   \"val\",   max(64, BC.examples_per_shard//2)),\n","    \"test\":  shard_writer(TFRECORDS_DIR / \"test\",  \"test\",  max(64, BC.examples_per_shard//2)),\n","}\n","\n","# cache GT vocals per track (avoid re-reading many times)\n","gt_cache = {}  # name -> (y_mono, sr)\n","\n","def get_gt_vocals(track_name: str):\n","    if track_name in gt_cache:\n","        return gt_cache[track_name]\n","    mt = name2track.get(track_name, None)\n","    assert mt is not None, f\"Track not found in MUSDB: {track_name}\"\n","    # gt vocals: (T, C), float\n","    y = mt.targets['vocals'].audio\n","    if y.ndim == 2:\n","        y = y.mean(axis=1)\n","    gt_cache[track_name] = (y.astype(np.float32), int(mt.rate))\n","    return gt_cache[track_name]\n","\n","# build\n","examples_total = {\"train\":0, \"val\":0, \"test\":0}\n","bad = 0\n","\n","for track_name, group in tqdm(segs.groupby(\"track\"), desc=\"Writing TFRecords by track\"):\n","    # Load Demucs mono once\n","    in_path = STEMS_DIR / track_name / \"vocals.mono.wav\"\n","    x_in, sr_in = read_wav_mono(in_path)\n","    # GT vocals\n","    x_gt, sr_gt = get_gt_vocals(track_name)\n","\n","    # Process each accepted segment -> window into fixed examples\n","    for _, row in group.iterrows():\n","        start_s, end_s = float(row.start_s), float(row.end_s)\n","        # Slice seconds\n","        seg_in = slice_sec(x_in, sr_in, start_s, end_s)\n","        seg_gt = slice_sec(x_gt, sr_gt, start_s, end_s)\n","\n","        # Resample both to training SR\n","        seg_in, _ = resample_if_needed(seg_in, sr_in, BC.train_sr)\n","        seg_gt, _ = resample_if_needed(seg_gt, sr_gt, BC.train_sr)\n","\n","        # Window into fixed win_s with hop_s\n","        N = len(seg_in)\n","        win = int(round(BC.win_s * BC.train_sr))\n","        hop = int(round(BC.hop_s * BC.train_sr))\n","        if N < win:\n","            # skip tiny segments\n","            continue\n","        for a in range(0, N - win + 1, hop):\n","            b = a + win\n","            xin = seg_in[a:b]\n","            xgt = seg_gt[a:b]\n","            # quick loudness sanity (skip near-silence)\n","            if rms_db(xin) < BC.min_rms_db or rms_db(xgt) < BC.min_rms_db:\n","                continue\n","            example = make_example(xin, xgt, BC.train_sr, track_name, start_s + a/BC.train_sr, start_s + b/BC.train_sr, split_of(track_name))\n","            write, close = writers[split_of(track_name)]\n","            write(example)\n","            examples_total[split_of(track_name)] += 1\n","\n","# Close writers\n","for _, (_, close) in writers.items():\n","    close()\n","\n","print(\"✅ Done.\")\n","print(\"Examples written:\", examples_total)\n"],"metadata":{"id":"PMwSGLYUt7bM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758483983084,"user_tz":360,"elapsed":965794,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"fbc95748-bb5c-47d1-8589-64ade6f31587"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Writing TFRecords by track: 100%|██████████| 149/149 [16:04<00:00,  6.47s/it]\n"]},{"output_type":"stream","name":"stdout","text":["✅ Done.\n","Examples written: {'train': 6811, 'val': 784, 'test': 4154}\n"]}]}]}