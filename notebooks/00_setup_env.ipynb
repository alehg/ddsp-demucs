{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOHXMcCf+QjEpqYdLOF8hS4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2cnsPw5dKlZ","executionInfo":{"status":"ok","timestamp":1756168741141,"user_tz":360,"elapsed":3048,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"c0c6b8eb-3f2a-4a53-867e-816d72329ef7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Project dir: /content/drive/MyDrive/ddsp-demucs\n","MUSDB18-HQ link present: True -> /content/drive/MyDrive/ddsp-demucs/data/musdb18hq\n"]}],"source":["#@title Mount Drive & define paths\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","from pathlib import Path\n","\n","PROJECT_DIR = Path('/content/drive/MyDrive/ddsp-demucs')\n","DATASETS_DIR = Path('/content/drive/MyDrive/datasets')  # keep big corpora here\n","MUSDB_HQ_SRC = DATASETS_DIR / 'musdb18hq'              # expected dataset location\n","\n","# Create project skeleton\n","for p in [\n","    PROJECT_DIR / 'data' / 'stems',\n","    PROJECT_DIR / 'data' / 'features',\n","    PROJECT_DIR / 'data' / 'tfrecords',\n","    PROJECT_DIR / 'exp',\n","    PROJECT_DIR / 'notebooks',\n","    PROJECT_DIR / 'env',\n","    PROJECT_DIR / 'src' / 'prepare',\n","    PROJECT_DIR / 'src' / 'train'\n","]:\n","    p.mkdir(parents=True, exist_ok=True)\n","\n","# Symlink dataset into project\n","MUSDB_LINK = PROJECT_DIR / 'data' / 'musdb18hq'\n","if MUSDB_HQ_SRC.exists():\n","    if not MUSDB_LINK.exists():\n","        MUSDB_LINK.symlink_to(MUSDB_HQ_SRC, target_is_directory=True)\n","else:\n","    print(\"⚠️ MUSDB18-HQ not found at\", MUSDB_HQ_SRC)\n","    print(\"  Please place WAV dataset at /MyDrive/datasets/musdb18hq\")\n","print(\"Project dir:\", PROJECT_DIR)\n","print(\"MUSDB18-HQ link present:\", MUSDB_LINK.exists(), \"->\", MUSDB_LINK)"]},{"cell_type":"code","source":["#@title Save config: dataset roots, paths, thresholds\n","import yaml\n","\n","cfg = {\n","    \"dataset\": {\n","        \"kind\": \"hq\",\n","        \"root\": str(MUSDB_LINK),\n","        \"sample_rate\": 44100\n","    },\n","    \"paths\": {\n","        \"project\": str(PROJECT_DIR),\n","        \"stems_dir\": str(PROJECT_DIR / \"data\" / \"stems\" / \"demucs_htdemucs44k\"),\n","        \"features_dir\": str(PROJECT_DIR / \"data\" / \"features\"),\n","        \"tfrecords_dir\": str(PROJECT_DIR / \"data\" / \"tfrecords\"),\n","        \"exp_dir\": str(PROJECT_DIR / \"exp\")\n","    },\n","    \"mono_downmix\": \"avg_lr\",   # (L+R)/2 for DDSP\n","    \"gate_thresholds\": {\n","        \"f0_conf_min\": 0.65,\n","        \"harmonicity_ratio_min\": 0.65,\n","        \"residual_energy_ratio_max\": 0.38,\n","        \"mono_frame_fraction_min\": 0.80,\n","        \"mono_track_fraction_min\": 0.88\n","    }\n","}\n","(PROJECT_DIR / \"env\").mkdir(parents=True, exist_ok=True)\n","with open(PROJECT_DIR / \"env\" / \"config.yaml\", \"w\") as f:\n","    yaml.safe_dump(cfg, f, sort_keys=False)\n","print(\"✅ Wrote config at\", PROJECT_DIR / \"env\" / \"config.yaml\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XPynUVMezv92","executionInfo":{"status":"ok","timestamp":1756170499429,"user_tz":360,"elapsed":43,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"29b78a47-6deb-4060-a2d9-9f8d765454b5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Wrote config at /content/drive/MyDrive/ddsp-demucs/env/config.yaml\n"]}]},{"cell_type":"code","source":["#@title Install libraries (separation, audio I/O, evaluation)\n","!pip -q install musdb museval stempeg demucs torchmetrics librosa soundfile torchaudio -U"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eee-FIGw6zS1","executionInfo":{"status":"ok","timestamp":1756170796633,"user_tz":360,"elapsed":276487,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"112bf545-7bb8-4fb8-923a-52bd24fea3dd"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.2 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.0/963.0 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.0/983.0 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for demucs (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for dora-search (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for treetable (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["#@title Record versions & GPU info\n","import importlib, platform, torch, json, sys\n","pkgs = ['musdb','museval','stempeg','demucs','librosa','soundfile','torch','torchmetrics']\n","vers = {}\n","for p in pkgs:\n","    try:\n","        m = importlib.import_module(p)\n","        v = getattr(m, '__version__', 'n/a')\n","    except Exception as e:\n","        v = f'load-failed: {e}'\n","    vers[p] = v\n","\n","env_info = {\n","    \"python\": sys.version,\n","    \"platform\": platform.platform(),\n","    \"gpu_available\": torch.cuda.is_available(),\n","    \"gpu_name\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,\n","    \"packages\": vers\n","}\n","with open(PROJECT_DIR / \"env\" / \"env_manifest.json\", \"w\") as f:\n","    json.dump(env_info, f, indent=2)\n","print(json.dumps(env_info, indent=2))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M7BuWfzu64XO","executionInfo":{"status":"ok","timestamp":1756171422877,"user_tz":360,"elapsed":19848,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"24c2748b-ddd7-4967-b182-a35b281a0e3f"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"python\": \"3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\",\n","  \"platform\": \"Linux-6.1.123+-x86_64-with-glibc2.35\",\n","  \"gpu_available\": false,\n","  \"gpu_name\": null,\n","  \"packages\": {\n","    \"musdb\": \"n/a\",\n","    \"museval\": \"n/a\",\n","    \"stempeg\": \"0.2.2\",\n","    \"demucs\": \"4.0.1\",\n","    \"librosa\": \"0.11.0\",\n","    \"soundfile\": \"0.13.1\",\n","    \"torch\": \"2.8.0+cu128\",\n","    \"torchmetrics\": \"1.8.1\"\n","  }\n","}\n"]}]},{"cell_type":"code","source":["#@title Verify dataset presence and load one WAV\n","import soundfile as sf\n","from pathlib import Path\n","import yaml\n","\n","with open(PROJECT_DIR / \"env\" / \"config.yaml\") as f:\n","    cfg = yaml.safe_load(f)\n","\n","root = Path(cfg['dataset']['root'])\n","assert root.exists(), f\"MUSDB root not found at {root}. Please ensure musdb18_hq is symlinked.\"\n","\n","# Try to find a mixture.wav\n","cand = sorted(root.glob(\"train/*/mixture.wav\"))[:1]\n","assert cand, \"Couldn't find train/*/mixture.wav under MUSDB18-HQ. Check dataset structure.\"\n","sig, sr = sf.read(str(cand[0]), always_2d=True)\n","print(\"✅ Loaded:\", cand[0].relative_to(root), \"| sr:\", sr, \"| shape:\", sig.shape)\n","\n","import torch\n","print(\"GPU:\", torch.cuda.is_available(), \"|\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU only\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9EXTow5i-VsI","executionInfo":{"status":"ok","timestamp":1756171464527,"user_tz":360,"elapsed":6920,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"6df5c69a-a9f8-4312-8c7a-3d5d3d4cb109"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Loaded: train/A Classic Education - NightOwl/mixture.wav | sr: 44100 | shape: (7560512, 2)\n","GPU: False | CPU only\n"]}]},{"cell_type":"code","source":["#@title Run tiny Demucs inference and save stereo+mono stems\n","import torchaudio, torch\n","from demucs.pretrained import get_model\n","from demucs.apply import apply_model\n","from pathlib import Path\n","import yaml\n","\n","with open(PROJECT_DIR / \"env\" / \"config.yaml\") as f:\n","    cfg = yaml.safe_load(f)\n","\n","mixture_path = cand[0]\n","wav, sr = torchaudio.load(str(mixture_path))  # shape: (2, T)\n","excerpt = wav[:, :sr*8]  # 8-second slice for quick test\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model = get_model('htdemucs').to(device).eval()\n","\n","with torch.inference_mode():\n","    # apply_model expects: (batch, channels, time)\n","    sources = apply_model(model, excerpt.unsqueeze(0).to(device), split=True, overlap=0.25)[0].cpu()\n","    # Demucs order: [drums, bass, other, vocals]\n","    vocals = sources[3]  # (2, T)\n","\n","stems_dir = Path(cfg[\"paths\"][\"stems_dir\"]) / \"SMOKE_TEST\"\n","stems_dir.mkdir(parents=True, exist_ok=True)\n","torchaudio.save(str(stems_dir / \"vocals.stereo.wav\"), vocals, sr)\n","torchaudio.save(str(stems_dir / \"vocals.mono.wav\"), vocals.mean(0, keepdim=True), sr)\n","\n","print(\"✅ Saved Demucs stems to:\", stems_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YEul7bPz-dLt","executionInfo":{"status":"ok","timestamp":1756171552297,"user_tz":360,"elapsed":39851,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"ecf220b6-af49-40bd-8631-786f4cf7d9b8"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n","  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"]},{"output_type":"stream","name":"stdout","text":["Downloading: \"https://dl.fbaipublicfiles.com/demucs/hybrid_transformer/955717e8-8726e21a.th\" to /root/.cache/torch/hub/checkpoints/955717e8-8726e21a.th\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80.2M/80.2M [00:01<00:00, 42.2MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["✅ Saved Demucs stems to: /content/drive/MyDrive/ddsp-demucs/data/stems/demucs_htdemucs44k/SMOKE_TEST\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:247: UserWarning: torio.io._streaming_media_encoder.StreamingMediaEncoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n","  s = torchaudio.io.StreamWriter(uri, format=muxer, buffer_size=buffer_size)\n"]}]},{"cell_type":"code","source":["#@title Extract F0 with librosa.pyin and RMS loudness\n","import numpy as np, librosa, soundfile as sf, math, yaml\n","from pathlib import Path\n","\n","with open(PROJECT_DIR / \"env\" / \"config.yaml\") as f:\n","    cfg = yaml.safe_load(f)\n","stems_dir = Path(cfg[\"paths\"][\"stems_dir\"]) / \"SMOKE_TEST\"\n","\n","y, sr = sf.read(str(stems_dir / \"vocals.mono.wav\"))\n","if y.ndim > 1: y = y.mean(axis=1)\n","\n","# Optional: resample to speed up F0 (keep consistent later in your pipeline)\n","target_sr = min(sr, 22050)\n","if sr != target_sr:\n","    y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n","    sr = target_sr\n","\n","# pyin params for singing (tune later)\n","fmin, fmax = librosa.note_to_hz('C2'), librosa.note_to_hz('C7')\n","f0, voiced_flag, voiced_prob = librosa.pyin(y, fmin=fmin, fmax=fmax, sr=sr, frame_length=2048, hop_length=int(0.01*sr))\n","rms = librosa.feature.rms(y=y, frame_length=2048, hop_length=int(0.01*sr)).squeeze()\n","\n","print(f\"F0 frames: {np.sum(~np.isnan(f0))}/{len(f0)} voiced | Median F0 (Hz): {np.nanmedian(f0):.1f}\")\n","print(f\"RMS frames: {len(rms)} | Voiced prob (mean): {np.nanmean(voiced_prob):.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WBR5LqBI-qn5","executionInfo":{"status":"ok","timestamp":1756172030365,"user_tz":360,"elapsed":32925,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"bd8d8035-870e-44d8-9871-3b4273419c51"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["F0 frames: 604/802 voiced | Median F0 (Hz): 226.4\n","RMS frames: 802 | Voiced prob (mean): 0.362\n"]}]},{"cell_type":"code","source":["import numpy as np, librosa, torchaudio\n","\n","# Load GT & estimate\n","gt_wav, sr = torchaudio.load(str(mixture_path.with_name('vocals.wav')))\n","est_wav, _  = torchaudio.load(str(stems_dir / \"vocals.mono.wav\"))\n","gt = gt_wav.mean(0).numpy()\n","est = est_wav.mean(0).numpy()\n","T = min(len(gt), len(est)); gt = gt[:T]; est = est[:T]\n","\n","# Pick a voiced region from GT (avoid silence)\n","rms = librosa.feature.rms(y=gt, frame_length=2048, hop_length=512).squeeze()\n","th = rms.max()*0.2  # 20% of max as a quick gate\n","mask = (rms > th).astype(np.float32)\n","if mask.sum() == 0:\n","    print(\"No voiced region found in excerpt—choose a different segment.\")\n","else:\n","    # choose the largest contiguous voiced chunk (~5–10s)\n","    hop = 512; idx = np.where(mask)[0]\n","    start_f, end_f = idx[0], idx[-1]\n","    start, end = start_f*hop, min(len(gt), (end_f+1)*hop)\n","    gt_v, est_v = gt[start:end], est[start:end]\n","\n","    def si_sdr(x, s, eps=1e-8):\n","        alpha = (x @ s) / (s @ s + eps)\n","        e_t = alpha * s\n","        e_n = x - e_t\n","        return 10*np.log10((np.sum(e_t**2)+eps)/(np.sum(e_n**2)+eps))\n","    print(\"SI-SDR on voiced segment (dB):\", si_sdr(est_v, gt_v))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F3uwgJA-AhB1","executionInfo":{"status":"ok","timestamp":1756175417203,"user_tz":360,"elapsed":563,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"ae4e308d-6d3a-4d16-b9ee-32db08f04ba9"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["SI-SDR on voiced segment (dB): 8.483761\n"]}]},{"cell_type":"code","source":["#@title Set seeds and freeze requirements\n","import os, random, numpy as np, torch\n","\n","SEED = 1337\n","random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)\n","os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n","\n","with open(PROJECT_DIR / \"env\" / \"seed.txt\", \"w\") as f:\n","    f.write(str(SEED))\n","print(\"✅ Seed set:\", SEED)\n","\n","!pip freeze > \"{PROJECT_DIR}/env/requirements_freeze.txt\"\n","with open(PROJECT_DIR / \"env\" / \"README_env.md\", \"w\") as f:\n","    f.write(\"\"\"# Environment Notes\n","- Run this notebook first in every new Colab runtime.\n","- Datasets live under /MyDrive/datasets, symlinked into data/.\n","- Heavy/conflicting installs (e.g., TensorFlow + DDSP, or CREPE) are done in their own notebooks (e.g., 04_train_ddsp.ipynb).\n","- All outputs go under data/ and exp/.\n","\"\"\")\n","print(\"✅ Wrote env/requirements_freeze.txt and env/README_env.md\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2oqAoDIwA1mz","executionInfo":{"status":"ok","timestamp":1756175458664,"user_tz":360,"elapsed":3052,"user":{"displayName":"Alejandro Hernández","userId":"17188197764876242129"}},"outputId":"a77aa4aa-f471-4c23-e4d7-58b3d47b39bc"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Seed set: 1337\n","✅ Wrote env/requirements_freeze.txt and env/README_env.md\n"]}]}]}