{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNUpxtgGH0likzm0YalJEWW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Remove RAPIDS & TF families that cause dependency conflicts in Colab\n","!pip -q uninstall -y \\\n","  cudf-cu12 cuml-cu12 cugraph-cu12 dask-cudf-cu12 dask-cuda rapids-dask-dependency \\\n","  distributed-ucxx-cu12 ucx-py-cu12 rmm-cu12 cudf-cu12 cuvs-cu12 cupy-cuda12x raft-dask-cu12 nx-cugraph-cu12 \\\n","  pylibcugraph-cu12 pylibraft-cu12 ucxx-cu12 \\\n","  tensorflow tensorflow-text tensorflow-decision-forests tf-keras keras keras-hub tensorflow-hub \\\n","  ddsp crepe || true\n","\n","# Fresh packaging toolchain\n","!pip -q install -U pip setuptools wheel build jedi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"29w9EBLshUN9","executionInfo":{"status":"ok","timestamp":1759275132858,"user_tz":360,"elapsed":5540,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}},"outputId":"aec76b66-a2a6-42ff-bc0b-20abded6e309","collapsed":true},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping cudf-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping cuml-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping cugraph-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping dask-cudf-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping dask-cuda as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping rapids-dask-dependency as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping distributed-ucxx-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping ucx-py-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping rmm-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping cuvs-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping cupy-cuda12x as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping raft-dask-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping nx-cugraph-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping pylibcugraph-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping pylibraft-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping ucxx-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping tensorflow-text as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping tensorflow-decision-forests as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping keras-hub as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping tensorflow-hub as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping crepe as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["# Fresh NumPy/SciPy\n","!pip -q install --no-cache-dir --force-reinstall \"numpy==2.1.3\" \"scipy==1.14.1\"\n","\n","# numba compatible with NumPy 2.1.x (needed by librosa/resampy/etc.)\n","!pip -q install -U \"numba==0.62.0\"\n","\n","# Audio + utils\n","!pip -q install -U librosa soundfile absl-py\n","\n","# JAX + ecosystem\n","!pip -q install -U \"jax[cpu]>=0.4.28\" \"flax>=0.8.2\" \"optax>=0.2.2\" chex orbax-checkpoint gin-config clu\n","\n","# TensorFlow stack that works on Py3.12 and satisfies DDSP/TFP imports\n","!pip -q install -U \"tensorflow==2.20.0\" \"tf-keras==2.20.0\" \"tensorflow-probability==0.25.0\"\n","\n","# Silence CPU runtimes warning if present\n","!pip -q uninstall -y jax-cuda12-plugin -q || true\n","\n","# Install DDSP source without its pinned (outdated) requirements\n","!pip -q install --no-deps \"git+https://github.com/magenta/ddsp@main#egg=ddsp\"\n","\n","# f0 extractor (replacement for CREPE)\n","!pip -q install -U torch torchcrepe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kbdn4fkbwshM","executionInfo":{"status":"ok","timestamp":1759275226882,"user_tz":360,"elapsed":61824,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}},"outputId":"eb3a3d8f-8f5b-4be2-9559-77050bac5f9f","collapsed":true},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n","dopamine-rl 4.1.2 requires tf-keras>=2.18.0, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'tf-keras' candidate (version 2.20.0 at https://files.pythonhosted.org/packages/50/9b/136dcabd535d98ce3729f6520fdfc6c8949e6209a7a847b067e114216deb/tf_keras-2.20.0-py3-none-any.whl (from https://pypi.org/simple/tf-keras/) (requires-python:>=3.9))\n","Reason for being yanked: <none given>\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping jax-cuda12-plugin as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33m  DEPRECATION: Building 'ddsp' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'ddsp'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n","\u001b[0m  Building wheel for ddsp (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["import os\n","os.environ.setdefault(\"TF_GPU_ALLOCATOR\", \"cuda_malloc_async\")  # helps fragmentation\n","\n","import tensorflow as tf\n","# Let TF allocate GPU memory gradually\n","for gpu in tf.config.list_physical_devices(\"GPU\"):\n","    try:\n","        tf.config.experimental.set_memory_growth(gpu, True)\n","    except Exception as e:\n","        print(\"Could not set memory growth:\", e)\n","\n","# Mixed precision halves activation memory on GPU\n","from tensorflow.keras import mixed_precision\n","mixed_precision.set_global_policy(\"mixed_float16\")\n","\n","print(\"Policy:\", mixed_precision.global_policy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOtT_MjzRXCU","executionInfo":{"status":"ok","timestamp":1759275369529,"user_tz":360,"elapsed":11,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}},"outputId":"f609c850-7290-43c3-8c86-3f7ce4a9c839"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Policy: <DTypePolicy \"mixed_float16\">\n"]}]},{"cell_type":"code","source":["# Provide a tiny 'crepe' module so ddsp.losses can import; we won't call it.\n","import sys, types\n","_crepe = types.ModuleType(\"crepe\")\n","def _predict_stub(*args, **kwargs):\n","    raise RuntimeError(\"ddsp.losses tried to call crepe.predict; use torchcrepe for f0 instead.\")\n","_crepe.predict = _predict_stub\n","sys.modules[\"crepe\"] = _crepe\n","\n","# Smoke test\n","import numpy as np, librosa, soundfile, torch, torchcrepe\n","import tensorflow_probability as tfp\n","import jax, flax, ddsp\n","\n","print(\"numpy:\", np.__version__)\n","print(\"TF / TFP:\", tf.__version__, \"/\", tfp.__version__)\n","print(\"jax / flax:\", jax.__version__, \"/\", flax.__version__)\n","print(\"ddsp:\", ddsp.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qevu4LG8nx0c","executionInfo":{"status":"ok","timestamp":1759275371586,"user_tz":360,"elapsed":7,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}},"outputId":"b2f1e148-da5f-407f-e0c1-a3cf8070b923"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["numpy: 2.1.3\n","TF / TFP: 2.20.0 / 0.25.0\n","jax / flax: 0.7.2 / 0.12.0\n","ddsp: 3.7.0\n"]}]},{"cell_type":"code","source":["#@title Mount & paths\n","from google.colab import drive\n","from pathlib import Path\n","import yaml, json, math, time\n","\n","drive.mount('/content/drive', force_remount=True)\n","\n","PROJECT_DIR = Path('/content/drive/MyDrive/ddsp-demucs')\n","CFG = yaml.safe_load(open(PROJECT_DIR / 'env' / 'config.yaml'))\n","\n","TFRECORDS_DIR = Path(CFG['paths']['tfrecords_dir'])\n","EXP_DIR = Path(CFG['paths']['exp_dir']) / 'run_ddsp_001'\n","EXP_DIR.mkdir(parents=True, exist_ok=True)\n","\n","print(\"TFRecords:\", TFRECORDS_DIR)\n","print(\"Exp:\", EXP_DIR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0aIs94hnSNTa","executionInfo":{"status":"ok","timestamp":1759276096176,"user_tz":360,"elapsed":3473,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}},"outputId":"9d4194d7-3abe-4969-f099-1e7e816e673b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","TFRecords: /content/drive/MyDrive/ddsp-demucs/data/tfrecords\n","Exp: /content/drive/MyDrive/ddsp-demucs/exp/run_ddsp_001\n"]}]},{"cell_type":"code","source":["#@title TFRecord parsing and feature extraction (torchcrepe f0)\n","import ddsp\n","from ddsp.spectral_ops import compute_loudness\n","# --- single source of truth ---\n","SR = 16000\n","WIN_S = 1.0\n","\n","FRAME_RATE = 250                  # <- your features‚Äô fps\n","HOP_SIZE = int(round(SR / FRAME_RATE))  # ‚âà88 samples\n","TPRIME = int(WIN_S * FRAME_RATE)  # 1.0s * 250 = 250\n","AUDIO_SAMPLES = int(WIN_S * SR)   # 1.0s * 16000 = 16000\n","\n","feature_description = {\n","    \"audio/inputs\":  tf.io.FixedLenFeature([], tf.string),\n","    \"audio/targets\": tf.io.FixedLenFeature([], tf.string),\n","    \"audio/sample_rate\": tf.io.FixedLenFeature([], tf.int64),\n","    \"audio/length\":      tf.io.FixedLenFeature([], tf.int64),\n","    \"meta/track\":   tf.io.FixedLenFeature([], tf.string),\n","    \"meta/subset\":  tf.io.FixedLenFeature([], tf.string),\n","}\n","\n","def _parse_ex(serialized):\n","    ex = tf.io.parse_single_example(serialized, feature_description)\n","    sr = tf.cast(ex[\"audio/sample_rate\"], tf.int32)\n","    xin = tf.io.decode_raw(ex[\"audio/inputs\"], tf.float32)\n","    xgt = tf.io.decode_raw(ex[\"audio/targets\"], tf.float32)\n","    xin.set_shape([None]); xgt.set_shape([None])\n","    return xin, xgt, sr, ex[\"meta/track\"], ex[\"meta/subset\"]\n","\n","# torchcrepe f0 wrapper\n","import torch\n","import torchcrepe\n","import numpy as np\n","\n","def torchcrepe_f0(audio_1d: np.ndarray, sr: int, hop_length: int = HOP_SIZE,\n","                  fmin: float = 50., fmax: float = 1100.) -> np.ndarray:\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    x = torch.tensor(audio_1d, dtype=torch.float32, device=device)[None]  # [1, T]\n","    with torch.no_grad():\n","        f0 = torchcrepe.predict(\n","            x, sr, hop_length,\n","            torch.tensor([fmin], device=device),\n","            torch.tensor([fmax], device=device),\n","            model=\"full\", batch_size=1024, device=device, return_periodicity=False\n","        )[0].cpu().numpy()  # [frames]\n","    # Replace NaNs/Infs\n","    f0 = np.where(np.isfinite(f0), f0, 0.0)\n","    return f0\n","\n","@tf.function\n","def _pad_or_trim_1d(x, T):\n","    x = x[:T]\n","    paddings = [[0, tf.maximum(0, T - tf.shape(x)[0])]]\n","    return tf.pad(x, paddings)\n","\n","def make_example(xin, xgt, sr, track, subset):\n","    # Fix length to window duration\n","    T = int(round(WIN_S * SR))\n","    xin = _pad_or_trim_1d(xin, T)\n","    xgt = _pad_or_trim_1d(xgt, T)\n","\n","    # Compute f0 with torchcrepe (in numpy, then back to tf)\n","    xin_np = xin.numpy() if isinstance(xin, tf.Tensor) else xin\n","    f0_np = torchcrepe_f0(np.array(xin_np, dtype=np.float32), SR, HOP_SIZE)\n","    f0_hz = tf.convert_to_tensor(f0_np, dtype=tf.float32)\n","\n","    # Loudness (A-weighted) using DDSP; expects [batch, time]\n","    x_b = tf.expand_dims(xin, 0)\n","    ld = compute_loudness(x_b, sample_rate=SR, frame_rate=FRAME_RATE, use_tf=True, ref_db=20.7)\n","    ld = tf.squeeze(ld, 0)\n","\n","    cond = {\"f0_hz\": f0_hz, \"loudness_db\": ld}\n","    return cond, xgt\n","\n","def dataset_from_dir(split, batch_size=8, shuffle=True):\n","    # inside dataset_from_dir(...)\n","    READ_PAR = 1                      # was AUTOTUNE; 1 is safer on RAM\n","    SHUFFLE_BUF = 512                 # was 4096\n","    MAP_PAR = 2                       # keep low, bump later if stable\n","\n","    files = sorted((TFRECORDS_DIR / split).glob(\"*.tfrecord\"))\n","    ds = tf.data.TFRecordDataset([str(p) for p in files],\n","                                num_parallel_reads=READ_PAR,\n","                                buffer_size=64*1024)  # default is 262,144; lower a bit\n","\n","    if shuffle:\n","        ds = ds.shuffle(SHUFFLE_BUF, reshuffle_each_iteration=True)\n","\n","    ds = ds.map(_parse_ex, num_parallel_calls=MAP_PAR, deterministic=False)\n","\n","\n","    # wrapper that returns only plain ndarrays, not dicts / tensors\n","    def _make_numpy(xin, xgt, sr, track, subset):\n","        # convert TF tensors to numpy for py_function\n","        xin_np    = np.array(xin)\n","        xgt_np    = np.array(xgt)\n","        sr_np     = np.array(sr).item()   # scalar\n","        track_np  = np.array(track).item()  # if scalar/string id\n","        subset_np = np.array(subset).item()\n","\n","        # your current make_example(...) likely returns (cond_dict, target)\n","        # change it (or adapt here) to return (f0_hz, loudness_db, target)\n","        f0_hz, loud_db, target = make_example(xin_np, xgt_np, sr_np, track_np, subset_np)\n","        return (f0_hz.astype('float32'),\n","                loud_db.astype('float32'),\n","                target.astype('float32'))\n","\n","    def _map_py(xin, xgt, sr, track, subset):\n","        f0_hz, loud_db, target = tf.py_function(\n","            func=_make_numpy,\n","            inp=[xin, xgt, sr, track, subset],\n","            Tout=(tf.float32, tf.float32, tf.float32)\n","        )\n","        # shapes are unknown after py_function; set them\n","        f0_hz.set_shape([None])\n","        loud_db.set_shape([None])\n","        target.set_shape([None])\n","\n","        cond = {\"f0_hz\": f0_hz, \"loudness_db\": loud_db}\n","        return cond, target\n","\n","    ds = ds.map(_map_py, num_parallel_calls=tf.data.AUTOTUNE)\n","\n","    # If all examples have equal frame length, regular batch is fine.\n","    # If lengths vary, use padded_batch instead of batch.\n","    ds = ds.batch(batch_size, drop_remainder=True)\n","    ds = ds.prefetch(tf.data.AUTOTUNE)\n","    return ds\n","\n","BATCH = 8\n","train_ds = dataset_from_dir(\"train\", batch_size=BATCH, shuffle=True)\n","val_ds   = dataset_from_dir(\"val\",   batch_size=BATCH, shuffle=False)"],"metadata":{"id":"18QLO6QFzTmB","executionInfo":{"status":"ok","timestamp":1759274657121,"user_tz":360,"elapsed":940,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def _pad_crop_time(x, length):\n","    # x: [B, T]  -> [B, length]\n","    t = tf.shape(x)[1]\n","    x = x[:, :length]\n","    pad = tf.maximum(0, length - tf.shape(x)[1])\n","    x = tf.pad(x, [[0, 0], [0, pad]])\n","    x = tf.ensure_shape(x, [None, length])\n","    return x\n","\n","def _pad_crop_audio(y, length):\n","    # y: [B, N] -> [B, length]\n","    n = tf.shape(y)[1]\n","    y = y[:, :length]\n","    pad = tf.maximum(0, length - tf.shape(y)[1])\n","    y = tf.pad(y, [[0, 0], [0, pad]])\n","    y = tf.ensure_shape(y, [None, length])\n","    return y\n","\n","def fix_batch_shapes(cond, target):\n","    cond = dict(cond)  # avoid side-effects\n","    cond['f0_hz']      = _pad_crop_time(cond['f0_hz'], TPRIME)\n","    cond['loudness_db'] = _pad_crop_time(cond['loudness_db'], TPRIME)\n","    target = _pad_crop_audio(target, AUDIO_SAMPLES)\n","    return cond, target\n","\n","\n","# Make sure train_ds and val_ds are already batched before this map.\n","train_ds = train_ds.map(fix_batch_shapes, num_parallel_calls=1).prefetch(1)\n","val_ds   = val_ds.map(fix_batch_shapes,   num_parallel_calls=1).prefetch(1)"],"metadata":{"id":"SyFctCTHicsb","executionInfo":{"status":"ok","timestamp":1759264372714,"user_tz":360,"elapsed":333,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def _pad_crop_time(x, length):\n","    # x: [B, T] -> [B, length]\n","    x = tf.convert_to_tensor(x)\n","    tf.debugging.assert_rank(x, 2, message=\"f0/loudness must be [B,T]\")\n","    x = x[:, :length]\n","    pad = tf.maximum(0, length - tf.shape(x)[1])\n","    x = tf.pad(x, [[0, 0], [0, pad]])\n","    x = tf.ensure_shape(x, [None, length])\n","    return x\n","\n","def _pad_crop_audio(y, length):\n","    # Accept [B, N] or [B, N, C]. If 3D, collapse channels to mono by mean.\n","    y = tf.convert_to_tensor(y)\n","    rank = tf.rank(y)\n","\n","    def _from_2d():\n","        return y  # [B, N]\n","\n","    def _from_3d():\n","        # [B, N, C] -> [B, N] (mono)\n","        return tf.reduce_mean(y, axis=-1)\n","\n","    y = tf.cond(tf.equal(rank, 2), _from_2d, _from_3d)\n","    # Now y is [B, N]\n","    y = y[:, :length]\n","    pad = tf.maximum(0, length - tf.shape(y)[1])\n","    y = tf.pad(y, [[0, 0], [0, pad]])\n","    y = tf.ensure_shape(y, [None, length])\n","    return y\n","\n","def fix_batch_shapes(cond, target):\n","    # Ensure dtypes and shapes after BATCHING.\n","    cond = {\n","        \"f0_hz\":      _pad_crop_time(tf.cast(cond[\"f0_hz\"], tf.float32), TPRIME),\n","        \"loudness_db\": _pad_crop_time(tf.cast(cond[\"loudness_db\"], tf.float32), TPRIME),\n","    }\n","    target = _pad_crop_audio(tf.cast(target, tf.float32), AUDIO_SAMPLES)\n","    return cond, target\n","\n","# If you control the builder, also shrink shuffle/reads there.\n","# Regardless, clamp the ready-made datasets here:\n","clamp_shuffle = 256     # keep small\n","def clamp(ds, do_shuffle=False):\n","    if do_shuffle:\n","        ds = ds.shuffle(clamp_shuffle, reshuffle_each_iteration=True)\n","    ds = ds.map(fix_batch_shapes, num_parallel_calls=1, deterministic=False)\n","    ds = ds.prefetch(1)\n","    return ds\n","\n","train_ds = clamp(train_ds, do_shuffle=True)\n","val_ds   = clamp(val_ds,   do_shuffle=False)"],"metadata":{"id":"yGcvVdtUSBrJ","executionInfo":{"status":"ok","timestamp":1759264577538,"user_tz":360,"elapsed":227,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#@title Build harmonic+noise+reverb model (Keras)\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras import mixed_precision\n","\n","\n","from ddsp.synths import Harmonic, FilteredNoise\n","from ddsp.effects import Reverb\n","from ddsp.losses import SpectralLoss\n","\n","N_HARMONICS = 32\n","N_NOISE_BANDS = 33\n","\n","class DDSPDecoder(keras.Model):\n","    def __init__(self, rnn_units=256, mlp_units=(256, 128), **kwargs):\n","        super().__init__(**kwargs)\n","        self.f0midi_range = (24.0, 84.0)  # clip to [C1, C6]\n","\n","        self.pre  = keras.layers.Dense(128, activation='relu')\n","        self.gru  = keras.layers.GRU(rnn_units, return_sequences=True)\n","        self.post = keras.Sequential([keras.layers.Dense(u, activation='relu') for u in mlp_units])\n","\n","        self.amp_head   = keras.layers.Dense(1)              # harmonic amplitude\n","        self.harm_head  = keras.layers.Dense(N_HARMONICS)    # harmonic distribution\n","        self.noise_head = keras.layers.Dense(N_NOISE_BANDS)  # noise magnitudes\n","\n","        # Effects and synths\n","        self.reverb = Reverb(trainable=True)\n","        self.harm = Harmonic(sample_rate=SR, amp_resample_method='linear')\n","        self.noise = FilteredNoise(\n","            n_samples=int(round(WIN_S * SR)),                 # fixed-length windows\n","            scale_fn=ddsp.core.exp_sigmoid, initial_bias=-5.0\n","        )\n","\n","    def call(self, inputs, training=False):\n","      # --- unify dtypes for features ---\n","      # Use the layer's compute dtype (float16 if mixed precision is on)\n","      comp_dtype = self.compute_dtype or tf.float32\n","\n","      # Cast inputs to comp_dtype for the stack / MLP\n","      f0_hz = tf.cast(inputs[\"f0_hz\"], comp_dtype)         # [B, T]\n","      ld_db = tf.cast(inputs[\"loudness_db\"], comp_dtype)   # [B, T]\n","\n","      # Compute f0_midi in float32 for numerical stability, then cast back\n","      f0_midi32 = ddsp.core.hz_to_midi(tf.cast(f0_hz, tf.float32))\n","      f0_midi32 = tf.clip_by_value(f0_midi32, *self.f0midi_range)\n","      f0_midi = tf.cast(f0_midi32, comp_dtype)\n","\n","      # Now both tensors have the same dtype -> stack is happy\n","      x = tf.stack([f0_midi, ld_db], axis=-1)   # [B, T, 2]\n","      x = self.pre(x)\n","      x = self.gru(x)\n","      x = self.post(x)\n","\n","      # Heads run in comp_dtype; do DSP scalings in float32, then cast if needed\n","      amp_head  = tf.cast(self.amp_head(x),  tf.float32)\n","      harm_log  = tf.cast(self.harm_head(x), tf.float32)\n","      noise_head= tf.cast(self.noise_head(x),tf.float32)\n","\n","      amp       = ddsp.core.exp_sigmoid(amp_head)               # [B, T, 1] float32\n","      harm_dist = tf.nn.softmax(harm_log, axis=-1)              # [B, T, H] float32\n","      noise_mag = ddsp.core.exp_sigmoid(noise_head)             # [B, T, BANDS] float32\n","\n","      f0_hz_3d  = tf.cast(f0_hz, tf.float32)[..., tf.newaxis]   # [B, T, 1] float32\n","\n","      # DDSP synths in float32\n","      audio_h = self.harm(amplitudes=amp, harmonic_distribution=harm_dist, f0_hz=f0_hz_3d)\n","      audio_n = self.noise(magnitudes=noise_mag)\n","\n","      # Align lengths if needed\n","      min_len = tf.minimum(tf.shape(audio_h)[-1], tf.shape(audio_n)[-1])\n","      audio_h = audio_h[..., :min_len]\n","      audio_n = audio_n[..., :min_len]\n","\n","      audio = audio_h + audio_n\n","      audio = self.reverb(audio)        # Reverb also in float32\n","\n","      # If the layer is running under mixed precision and you want to return fp16:\n","      # return tf.cast(audio, comp_dtype)\n","      return audio                       # keep float32; cast in loss if needed\n","\n","\n","# Multi-scale spectral loss (linear mag)\n","loss_fn = SpectralLoss(\n","    fft_sizes=(512, 256),\n","    loss_type='L1',\n","    mag_weight=1.0,\n","    logmag_weight=0.0,\n","    delta_time_weight=0.0,\n","    delta_freq_weight=0.0,\n","    cumsum_freq_weight=0.0,\n","    loudness_weight=0.0,\n","    name='spectral_loss'\n",")\n","\n","class DDSPTrainer(keras.Model):\n","    def __init__(self, ddsp_model, loss_fn):\n","        super().__init__()\n","        self.ddsp_model = ddsp_model\n","        self.loss_fn = loss_fn\n","\n","    def compile(self, optimizer):\n","        super().compile()\n","        self.optimizer = optimizer\n","        # Detect mixed-precision optimizer once (used inside tf.function)\n","        self._uses_loss_scale = hasattr(self.optimizer, \"get_scaled_loss\")\n","\n","    @tf.function\n","    def train_step(self, data):\n","        cond, target = data\n","        with tf.GradientTape() as tape:\n","            pred = self.ddsp_model(cond, training=True)\n","            # keep loss math in float32 for stability\n","            loss = self.loss_fn(tf.cast(target, tf.float32), tf.cast(pred, tf.float32))\n","            if self._uses_loss_scale:\n","                loss_to_minimize = self.optimizer.get_scaled_loss(loss)\n","            else:\n","                loss_to_minimize = loss\n","\n","        grads = tape.gradient(loss_to_minimize, self.ddsp_model.trainable_variables)\n","        if self._uses_loss_scale:\n","            grads = self.optimizer.get_unscaled_gradients(grads)\n","\n","        self.optimizer.apply_gradients(zip(grads, self.ddsp_model.trainable_variables))\n","        return {\"loss\": loss}\n","\n","    @tf.function\n","    def test_step(self, data):\n","        cond, target = data\n","        pred  = self.ddsp_model(cond, training=False)\n","        loss  = self.loss_fn(tf.cast(target, tf.float32), tf.cast(pred, tf.float32))\n","        return {\"val_loss\": loss}\n","\n","# Trainer + compile (unchanged)\n","model = DDSPDecoder()\n","# 3) Optimizer (works with or without mixed precision)\n","\n","use_mp = mixed_precision.global_policy().name == \"mixed_float16\"\n","base_opt = keras.optimizers.Adam(1e-3)\n","opt = mixed_precision.LossScaleOptimizer(base_opt) if use_mp else base_opt\n","\n","# 4) Trainer: pass the loss_fn\n","trainer = DDSPTrainer(model, loss_fn)\n","trainer.compile(optimizer=opt)"],"metadata":{"id":"Aza_oTrxzYzK","executionInfo":{"status":"ok","timestamp":1759265587849,"user_tz":360,"elapsed":6,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["Tprime = 250\n","dummy = {\n","    \"f0_hz\": tf.zeros([1, Tprime], dtype=tf.float32),\n","    \"loudness_db\": tf.zeros([1, Tprime], dtype=tf.float32),\n","}\n","_ = model(dummy, training=False)  # should run without the broadcast error now\n","print(\"Trainable params:\", sum(int(np.prod(v.shape)) for v in model.trainable_variables))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UguuCuXc4KEv","executionInfo":{"status":"ok","timestamp":1759265593347,"user_tz":360,"elapsed":505,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}},"outputId":"168e3b30-97d3-4e8c-d552-04a8263e7666"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Trainable params: 452034\n"]}]},{"cell_type":"code","source":["#@title Pre-train\n","import tensorflow as tf, tensorflow.keras as keras\n","LOG_DIR = EXP_DIR / \"tb\"\n","CKPT_DIR = EXP_DIR / \"ckpt\"\n","CKPT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","\n","# Recreate model & trainer after changes (and after a fresh restart if needed)\n","tf.keras.backend.clear_session()\n","model = DDSPDecoder()\n","use_mp = mixed_precision.global_policy().name == \"mixed_float16\"\n","base_opt = keras.optimizers.Adam(1e-3)\n","opt = mixed_precision.LossScaleOptimizer(base_opt) if use_mp else base_opt\n","\n","# 4) Trainer: pass the loss_fn\n","trainer = DDSPTrainer(model, loss_fn)\n","trainer.compile(optimizer=opt)\n","\n","# Build variables with a dummy pass (TPRIME frames)\n","_ = model({\"f0_hz\": tf.zeros([1, TPRIME]), \"loudness_db\": tf.zeros([1, TPRIME])}, training=False)\n","\n","# Minimal callbacks (disable TensorBoard for now to save memory)\n","callbacks = [\n","    keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5, restore_best_weights=True),\n","    # Save weights infrequently; Keras 3 requires .weights.h5\n","    keras.callbacks.ModelCheckpoint(filepath=str(CKPT_DIR / \"ddsp.best.weights.h5\"),\n","                                    save_weights_only=True, monitor=\"val_loss\", mode=\"min\", save_best_only=True)\n","]\n","\n","# If you control batching, set a small batch size upstream. Otherwise, cap steps here:\n","EPOCHS = 3\n","history = trainer.fit(\n","    train_ds.take(50),\n","    validation_data=val_ds.take(10),\n","    epochs=2,\n","    steps_per_epoch=25,\n","    validation_steps=5,\n","    verbose=1,\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aDkhjrsJS7EB","outputId":"fa23c25c-a1c7-43b1-bfef-92fa489c0b37"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n"]}]},{"cell_type":"code","source":["#@title Train!\n","LOG_DIR = EXP_DIR / \"tb\"\n","CKPT_DIR = EXP_DIR / \"ckpt\"\n","CKPT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath=str(CKPT_DIR / \"ddsp.best.weights.h5\"),  # <-- fix extension\n","        save_weights_only=True,\n","        monitor=\"val_loss\",\n","        mode=\"min\",\n","        save_best_only=True,\n","    ),\n","    keras.callbacks.EarlyStopping(\n","        monitor=\"val_loss\",\n","        mode=\"min\",\n","        patience=8,\n","        restore_best_weights=True,\n","    ),\n","    keras.callbacks.TensorBoard(\n","        log_dir=str(LOG_DIR), write_graph=False, update_freq=\"epoch\"\n","    ),\n","]\n","keras.callbacks.ModelCheckpoint(\n","    filepath=str(CKPT_DIR / \"ddsp.{epoch:03d}-{val_loss:.4f}.weights.h5\"),\n","    save_weights_only=True,\n","    monitor=\"val_loss\",\n","    mode=\"min\",\n","    save_best_only=True,\n",")\n","EPOCHS = 50\n","history = trainer.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=EPOCHS,\n","    callbacks=callbacks,\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x_eBg5mseKLn","outputId":"1f0a3532-3f4c-43a7-d591-a66f55e6d9f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n"]}]},{"cell_type":"markdown","source":["## Minimal Model"],"metadata":{"id":"oYWLOZHO48gN"}},{"cell_type":"code","source":["#@title Safe Runtime Setup\n","\n","# <<< RUN THIS AS YOUR FIRST CELL AFTER A RUNTIME RESTART >>>\n","import os\n","# Disable XLA (can trigger big graphs & crashes in some TF builds)\n","os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=0\"\n","# Let TF grow GPU memory gradually (works only if set before runtime heavy use)\n","os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n","# Reduce TF log noise\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","\n","import tensorflow as tf\n","from tensorflow.keras import mixed_precision\n","\n","# Make sure we're NOT in mixed precision while debugging stability\n","mixed_precision.set_global_policy(\"float32\")\n","print(\"Compute policy:\", mixed_precision.global_policy())\n","\n","# Also disable XLA via API (belt & suspenders)\n","tf.config.optimizer.set_jit(False)\n","\n","# Enable GPU memory growth\n","for gpu in tf.config.list_physical_devices(\"GPU\"):\n","    try:\n","        tf.config.experimental.set_memory_growth(gpu, True)\n","    except Exception as e:\n","        print(\"Could not set memory growth:\", e)\n","print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))\n"],"metadata":{"id":"HNH0UC43hPj7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759274667478,"user_tz":360,"elapsed":29,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}},"outputId":"7e64c508-ae06-4b5e-e143-eb9360917577"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Compute policy: <DTypePolicy \"float32\">\n","GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}]},{"cell_type":"code","source":["#@title Frugal Dataset\n","\n","# Single source of truth\n","SR = 16000\n","WIN_S = 0.5            # <<< half-second windows to minimize memory for the smoke test\n","FRAME_RATE = 250       # your features fps\n","TPRIME = int(WIN_S * FRAME_RATE)   # 125\n","AUDIO_SAMPLES = int(WIN_S * SR)    # 8000\n","\n","import tensorflow as tf\n","\n","def _pad_crop_time(x, length):\n","    x = tf.convert_to_tensor(x)\n","    tf.debugging.assert_rank(x, 2)\n","    x = x[:, :length]\n","    pad = tf.maximum(0, length - tf.shape(x)[1])\n","    x = tf.pad(x, [[0,0],[0,pad]])\n","    x = tf.ensure_shape(x, [None, length])\n","    return x\n","\n","def _pad_crop_audio(y, length):\n","    y = tf.convert_to_tensor(y)\n","    y = tf.cond(tf.equal(tf.rank(y), 2), lambda: y, lambda: tf.reduce_mean(y, axis=-1))\n","    y = y[:, :length]\n","    pad = tf.maximum(0, length - tf.shape(y)[1])\n","    y = tf.pad(y, [[0,0],[0,pad]])\n","    y = tf.ensure_shape(y, [None, length])\n","    return y\n","\n","def fix_batch_shapes(cond, target):\n","    cond = {\n","        \"f0_hz\":      _pad_crop_time(tf.cast(cond[\"f0_hz\"], tf.float32), TPRIME),\n","        \"loudness_db\": _pad_crop_time(tf.cast(cond[\"loudness_db\"], tf.float32), TPRIME),\n","    }\n","    target = _pad_crop_audio(tf.cast(target, tf.float32), AUDIO_SAMPLES)\n","    return cond, target\n","\n","# Clamp an existing dataset post-batch: tiny shuffle/prefetch, single-threaded map\n","clamp_shuffle = 64\n","def clamp(ds, do_shuffle=False):\n","    if do_shuffle:\n","        ds = ds.shuffle(clamp_shuffle, reshuffle_each_iteration=True)\n","    ds = ds.map(fix_batch_shapes, num_parallel_calls=1, deterministic=False)\n","    ds = ds.prefetch(0)   # no prefetch for the smoke test\n","    return ds\n","\n","# Force tiny batch size, even if upstream is bigger\n","def rebatch(ds, bs=1):\n","    return ds.unbatch().batch(bs, drop_remainder=True)\n","\n","# Apply to your existing datasets:\n","train_ds = clamp(rebatch(train_ds, bs=1), do_shuffle=True).take(8)   # 8 tiny batches max\n","val_ds   = clamp(rebatch(val_ds,   bs=1), do_shuffle=False).take(2)\n"],"metadata":{"id":"NtwcTpsY5Dxp","executionInfo":{"status":"ok","timestamp":1759274670936,"user_tz":360,"elapsed":305,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#@title Minimal Model\n","\n","import ddsp\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from ddsp.synths import Harmonic\n","\n","N_HARMONICS = 16   # tiny\n","\n","class DDSPDecoder(keras.Model):\n","    def __init__(self, rnn_units=64, mlp_units=(64,), **kwargs):\n","        super().__init__(**kwargs)\n","        self.f0midi_range = (24.0, 84.0)\n","        self.pre  = keras.layers.Dense(32, activation='relu')\n","        self.gru  = keras.layers.GRU(rnn_units, return_sequences=True)\n","        self.post = keras.Sequential([keras.layers.Dense(u, activation='relu') for u in mlp_units])\n","\n","        self.amp_head   = keras.layers.Dense(1)\n","        self.harm_head  = keras.layers.Dense(N_HARMONICS)\n","\n","        self.harm = Harmonic(sample_rate=SR, amp_resample_method='linear')\n","\n","    def call(self, inputs, training=False):\n","        # unify dtypes for safe stacking\n","        f0_hz = tf.cast(inputs[\"f0_hz\"], tf.float32)\n","        ld_db = tf.cast(inputs[\"loudness_db\"], tf.float32)\n","\n","        f0_midi = ddsp.core.hz_to_midi(tf.clip_by_value(f0_hz, 1.0, 8000.0))\n","        f0_midi = tf.clip_by_value(f0_midi, *self.f0midi_range)\n","\n","        x = tf.stack([f0_midi, ld_db], axis=-1)   # [B, T, 2]\n","        x = self.pre(x); x = self.gru(x); x = self.post(x)\n","\n","        amp       = ddsp.core.exp_sigmoid(self.amp_head(x))          # [B,T,1]\n","        harm_dist = tf.nn.softmax(tf.cast(self.harm_head(x), tf.float32), axis=-1)  # [B,T,H]\n","        f0_hz_3d  = f0_hz[..., tf.newaxis]                           # [B,T,1]\n","\n","        audio_h = self.harm(amplitudes=amp, harmonic_distribution=harm_dist, f0_hz=f0_hz_3d)\n","        return audio_h  # [B, N]\n"],"metadata":{"id":"jZHZ--px5JhO","executionInfo":{"status":"ok","timestamp":1759274709698,"user_tz":360,"elapsed":32,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#@title Small Spectral Loss\n","from ddsp.losses import SpectralLoss\n","\n","loss_fn = SpectralLoss(\n","    fft_sizes=(512, 256),   # small\n","    loss_type='L1',\n","    mag_weight=1.0,\n","    logmag_weight=0.0,\n","    delta_time_weight=0.0,\n","    delta_freq_weight=0.0,\n","    cumsum_freq_weight=0.0,\n","    loudness_weight=0.0,\n",")\n","\n","class DDSPTrainer(keras.Model):\n","    def __init__(self, ddsp_model, loss_fn):\n","        super().__init__()\n","        self.ddsp_model = ddsp_model\n","        self.loss_fn = loss_fn\n","\n","    # IMPORTANT: run eagerly to keep graphs small/stable for the smoke test\n","    def compile(self, optimizer):\n","        super().compile(run_eagerly=True)\n","        self.optimizer = optimizer\n","\n","    def train_step(self, data):\n","        cond, target = data\n","        with tf.GradientTape() as tape:\n","            pred = self.ddsp_model(cond, training=True)\n","            loss = self.loss_fn(tf.cast(target, tf.float32), tf.cast(pred, tf.float32))\n","        grads = tape.gradient(loss, self.ddsp_model.trainable_variables)\n","        self.optimizer.apply_gradients(zip(grads, self.ddsp_model.trainable_variables))\n","        return {\"loss\": loss}\n","\n","    def test_step(self, data):\n","        cond, target = data\n","        pred  = self.ddsp_model(cond, training=False)\n","        loss  = self.loss_fn(tf.cast(target, tf.float32), tf.cast(pred, tf.float32))\n","        return {\"val_loss\": loss}\n"],"metadata":{"id":"qmgkO_Sq8aQ0","executionInfo":{"status":"ok","timestamp":1759274729418,"user_tz":360,"elapsed":9,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#@title Build\n","tf.keras.backend.clear_session()\n","model = DDSPDecoder()\n","# build vars\n","_ = model({\"f0_hz\": tf.zeros([1, TPRIME], tf.float32),\n","           \"loudness_db\": tf.zeros([1, TPRIME], tf.float32)}, training=False)\n","\n","print(\"Trainable params:\", sum(int(tf.size(v)) for v in model.trainable_variables))\n","\n","opt = keras.optimizers.Adam(1e-3, clipnorm=1.0)  # clip for stability\n","trainer = DDSPTrainer(model, loss_fn)\n","trainer.compile(optimizer=opt)\n","\n","# No callbacks, no TensorBoard, tiny steps\n","history = trainer.fit(\n","    train_ds, validation_data=val_ds,\n","    epochs=1, steps_per_epoch=2, validation_steps=1, verbose=1\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jObY3dDk8f7Q","outputId":"ba1c424e-325d-473d-bb2a-1814a598a086"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trainable params: 24177\n"]}]},{"cell_type":"markdown","source":["### Baseline"],"metadata":{"id":"_WT_fq8V-xhd"}},{"cell_type":"code","source":["# --- hard reset setup ---\n","import os, tensorflow as tf, tensorflow.keras as keras, ddsp\n","from tensorflow.keras import mixed_precision\n","\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=0\"   # no XLA while stabilizing\n","mixed_precision.set_global_policy(\"float32\")         # keep dtypes simple\n","\n","for gpu in tf.config.list_physical_devices(\"GPU\"):\n","    try:\n","        tf.config.experimental.set_memory_growth(gpu, True)\n","    except Exception:\n","        pass\n","tf.config.optimizer.set_jit(False)\n","\n","SR, WIN_S, FRAME_RATE = 16000, 0.5, 250\n","TPRIME, AUDIO_SAMPLES = int(WIN_S*FRAME_RATE), int(WIN_S*SR)\n","\n","# --- tiny harmonic-only model (same as before) ---\n","from ddsp.synths import Harmonic\n","N_HARMONICS = 8\n","\n","class DDSPDecoder(keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        self.f0midi_range = (24.0, 84.0)\n","        self.pre  = keras.layers.Dense(16, activation='relu')\n","        self.gru  = keras.layers.GRU(32, return_sequences=True)\n","        self.post = keras.layers.Dense(16, activation='relu')\n","        self.amp_head  = keras.layers.Dense(1)\n","        self.harm_head = keras.layers.Dense(N_HARMONICS)\n","        try:\n","            self.harm = Harmonic(sample_rate=SR,\n","                                amp_resample_method='linear',\n","                                frame_rate=FRAME_RATE)        # preferred\n","        except TypeError:\n","            self.harm = Harmonic(sample_rate=SR,\n","                                amp_resample_method='linear')\n","            # fallback for older builds:\n","            self.harm.frame_rate = FRAME_RATE\n","\n","    def call(self, inputs, training=False):\n","        f0_hz = tf.cast(inputs[\"f0_hz\"], tf.float32)\n","        ld_db = tf.cast(inputs[\"loudness_db\"], tf.float32)\n","        f0_midi = ddsp.core.hz_to_midi(tf.clip_by_value(f0_hz, 1.0, 8000.0))\n","        f0_midi = tf.clip_by_value(f0_midi, *self.f0midi_range)\n","        x = tf.stack([f0_midi, ld_db], axis=-1)\n","        x = self.pre(x); x = self.gru(x); x = self.post(x)\n","        amp = ddsp.core.exp_sigmoid(self.amp_head(x))\n","        harm_dist = tf.nn.softmax(tf.cast(self.harm_head(x), tf.float32), axis=-1)\n","        audio = self.harm(amplitudes=amp, harmonic_distribution=harm_dist, f0_hz=f0_hz[..., tf.newaxis])\n","        return audio  # [B, N]\n","\n","# loss & trainer (eager to keep graphs small)\n","from ddsp.losses import SpectralLoss\n","loss_fn = SpectralLoss(fft_sizes=(512,256), loss_type='L1', mag_weight=1.0)\n","\n","class DDSPTrainer(keras.Model):\n","    def __init__(self, ddsp_model, loss_fn):\n","        super().__init__()\n","        self.net = ddsp_model          # avoid naming collisions with keras.Model\n","        self.loss_fn = loss_fn\n","\n","    def compile(self, optimizer):\n","        super().compile(run_eagerly=True)  # eager for stability in the smoke test\n","        self.optimizer = optimizer\n","\n","    def train_step(self, data):\n","        cond, target = data\n","        with tf.GradientTape() as tape:\n","            pred = self.net(cond, training=True)\n","            # üîí ensure identical lengths for loss\n","            pred   = pred[:, :AUDIO_SAMPLES]\n","            target = tf.cast(target[:, :AUDIO_SAMPLES], tf.float32)\n","            loss = self.loss_fn(target, tf.cast(pred, tf.float32))\n","        grads = tape.gradient(loss, self.net.trainable_variables)\n","        self.optimizer.apply_gradients(zip(grads, self.net.trainable_variables))\n","        return {\"loss\": loss}\n","\n","    def test_step(self, data):\n","        cond, target = data\n","        pred = self.net(cond, training=False)\n","        pred   = pred[:, :AUDIO_SAMPLES]\n","        target = tf.cast(target[:, :AUDIO_SAMPLES], tf.float32)\n","        loss = self.loss_fn(target, tf.cast(pred, tf.float32))\n","        return {\"val_loss\": loss}\n","\n","# --- in-memory toy dataset (no TFRecords at all) ---\n","import numpy as np\n","B = 1  # tiny batch\n","cond = {\"f0_hz\": tf.constant(np.zeros((B, TPRIME), np.float32)),\n","        \"loudness_db\": tf.constant(np.zeros((B, TPRIME), np.float32))}\n","target = tf.zeros([B, AUDIO_SAMPLES], tf.float32)\n","\n","toy = tf.data.Dataset.from_tensor_slices((cond, target)).repeat().batch(1)\n","\n","# build, print params, do 1-2 tiny steps\n","tf.keras.backend.clear_session()\n","model = DDSPDecoder()\n","_ = model({\"f0_hz\": tf.zeros([1, TPRIME]), \"loudness_db\": tf.zeros([1, TPRIME])}, training=False)\n","print(\"Trainable params:\", sum(int(tf.size(v)) for v in model.trainable_variables))\n","\n","trainer = DDSPTrainer(model, loss_fn)\n","trainer.compile(optimizer=keras.optimizers.Adam(1e-3))\n","history = trainer.fit(toy.take(2), validation_data=toy.take(1), epochs=1,\n","                      steps_per_epoch=2, validation_steps=1, verbose=1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PV_qzO7Z8sUX","executionInfo":{"status":"ok","timestamp":1759275731471,"user_tz":360,"elapsed":37440,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}},"outputId":"7c5f8ffb-fcfb-452f-8216-de453377b81f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Trainable params: 5529\n","\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366ms/step - loss: 0.0000e+00 - val_val_loss: 0.0000e+00\n"]}]},{"cell_type":"code","source":["import tensorflow as tf, pathlib\n","\n","# --- keep the same globals you used for the toy run ---\n","SR = 16000\n","WIN_S = 1                   # stay small for the smoke test\n","FRAME_RATE = 250\n","TPRIME = int(WIN_S * FRAME_RATE)   # 125\n","AUDIO_SAMPLES = int(WIN_S * SR)    # 8000\n","\n","# Point to just a FEW files to start\n","#TFRECORDS_DIR = pathlib.Path(\"/path/to/tfrecords\")     # <-- change this\n","train_files = sorted(map(str, (TFRECORDS_DIR / \"train\").glob(\"*.tfrecord\")))\n","val_files   = sorted(map(str, (TFRECORDS_DIR / \"val\").glob(\"*.tfrecord\")))\n","\n","# Robust parser that handles variable-length sequences\n","def _parse_ex(serialized):\n","    spec = {\n","        \"f0_hz\":       tf.io.VarLenFeature(tf.float32),\n","        \"loudness_db\": tf.io.VarLenFeature(tf.float32),\n","        \"audio\":       tf.io.VarLenFeature(tf.float32),\n","    }\n","    ex = tf.io.parse_single_example(serialized, spec)\n","    f0 = tf.sparse.to_dense(ex[\"f0_hz\"])\n","    ld = tf.sparse.to_dense(ex[\"loudness_db\"])\n","    y  = tf.sparse.to_dense(ex[\"audio\"])\n","    return {\"f0_hz\": f0, \"loudness_db\": ld}, y\n","\n","# Crop/pad to fixed sizes (matches the toy run)\n","def _pad_crop_time(x, length):\n","    x = x[:length]\n","    pad = tf.maximum(0, length - tf.shape(x)[0])\n","    x = tf.pad(x, [[0, pad]])\n","    return tf.ensure_shape(x, [length])\n","\n","def _pad_crop_audio(y, length):\n","    y = y[:length]\n","    pad = tf.maximum(0, length - tf.shape(y)[0])\n","    y = tf.pad(y, [[0, pad]])\n","    return tf.ensure_shape(y, [length])\n","\n","def _fix_shapes(cond, y):\n","    cond = {\n","        \"f0_hz\":      tf.cast(_pad_crop_time(cond[\"f0_hz\"], TPRIME), tf.float32),\n","        \"loudness_db\": tf.cast(_pad_crop_time(cond[\"loudness_db\"], TPRIME), tf.float32),\n","    }\n","    y = tf.cast(_pad_crop_audio(y, AUDIO_SAMPLES), tf.float32)\n","    return cond, y\n","\n","def make_ds(files):\n","    # ultra-conservative: single-threaded, tiny buffers, NO prefetch\n","    ds = tf.data.TFRecordDataset(\n","        files,\n","        num_parallel_reads=1,\n","        buffer_size=64*1024,          # 16KB ingest buffer\n","        compression_type=\"\"           # set \"GZIP\" if your files are gzipped\n","    )\n","    ds = ds.map(_parse_ex, num_parallel_calls=1, deterministic=True)\n","    ds = ds.map(_fix_shapes, num_parallel_calls=1, deterministic=True)\n","    ds = ds.batch(1, drop_remainder=True).shuffle(128)   # tiny batch to minimize memory\n","    ds = ds.prefetch(1)                        # cap the dataset while testing\n","    return ds\n","\n","train_ds_lean = make_ds(train_files)\n","val_ds_lean   = make_ds(val_files)\n"],"metadata":{"id":"6GUogBXfA5zg","executionInfo":{"status":"ok","timestamp":1759276827170,"user_tz":360,"elapsed":301,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["def peek(ds, n=1):\n","    it = iter(ds.take(n))\n","    cond, y = next(it)\n","    tf.print(\"peek shapes  f0:\", tf.shape(cond[\"f0_hz\"]),\n","             \"ld:\", tf.shape(cond[\"loudness_db\"]),\n","             \"y:\", tf.shape(y))\n","peek(train_ds_lean, 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWXOOqquA6PM","executionInfo":{"status":"ok","timestamp":1759276828717,"user_tz":360,"elapsed":195,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}},"outputId":"24dc0b64-2040-463e-cc31-a2f1d156470e"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["peek shapes  f0: [1 250] ld: [1 250] y: [1 16000]\n"]}]},{"cell_type":"code","source":["# Reuse your already-built model / loss / trainer from the toy run:\n","# model, loss_fn, DDSPTrainer (eager), etc.\n","\n","history = trainer.fit(\n","    train_ds_lean,\n","    validation_data=val_ds_lean,\n","    epochs=1,\n","    steps_per_epoch=2,\n","    validation_steps=1,\n","    verbose=1\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OGOBvALwB8Tl","executionInfo":{"status":"ok","timestamp":1759276830723,"user_tz":360,"elapsed":930,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}},"outputId":"dbeff50c-b472-4740-c91a-06a980ae18e0"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step - loss: 0.0000e+00 - val_val_loss: 0.0000e+00\n"]}]},{"cell_type":"code","source":["TRAIN_STEPS = 200   # how many batches you want per epoch (tweak)\n","VAL_STEPS   = 40\n","\n","from tensorflow.data import experimental as tfd\n","\n","train_run = train_ds_lean.take(TRAIN_STEPS).apply(tfd.assert_cardinality(TRAIN_STEPS))\n","val_run   = val_ds_lean.take(VAL_STEPS).apply(tfd.assert_cardinality(VAL_STEPS))\n","\n","history = trainer.fit(\n","    train_run,\n","    validation_data=val_run,\n","    epochs=1,\n","    steps_per_epoch=TRAIN_STEPS,\n","    validation_steps=VAL_STEPS,\n","    verbose=1,\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"528bFkPtES0e","executionInfo":{"status":"ok","timestamp":1759276993329,"user_tz":360,"elapsed":82141,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}},"outputId":"15e9370e-251b-4253-af82-c0d997b52db7"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m200/200\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 261ms/step - loss: 0.0000e+00 - val_val_loss: 0.0000e+00\n"]}]},{"cell_type":"code","source":["from pathlib import Path\n","\n","cand_patterns = [\"*.tfrecord\", \"*.tfrecords\", \"*.tfrec\", \"*.tfrec\", \"*.tfr\"]\n","train_dir = TFRECORDS_DIR / \"train\"\n","val_dir   = TFRECORDS_DIR / \"val\"\n","\n","def list_files(p):\n","    out=[]\n","    for pat in cand_patterns:\n","        out += list(p.glob(pat))\n","    return sorted(out)\n","\n","train_files = list_files(train_dir)\n","val_files   = list_files(val_dir)\n","\n","print(\"#train files:\", len(train_files))\n","print(\"#val files:\", len(val_files))\n","print(\"first few train:\", [str(p) for p in train_files[:3]])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZWRJeBTA9T6","executionInfo":{"status":"ok","timestamp":1759276114427,"user_tz":360,"elapsed":32,"user":{"displayName":"Alejandro Hern√°ndez","userId":"17188197764876242129"}},"outputId":"1870da3f-2c9a-49b7-9204-43582c60bb78"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["#train files: 14\n","#val files: 4\n","first few train: ['/content/drive/MyDrive/ddsp-demucs/data/tfrecords/train/train-00000.tfrecord', '/content/drive/MyDrive/ddsp-demucs/data/tfrecords/train/train-00001.tfrecord', '/content/drive/MyDrive/ddsp-demucs/data/tfrecords/train/train-00002.tfrecord']\n"]}]}]}